{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-04T18:27:19.078873Z",
     "iopub.status.busy": "2024-12-04T18:27:19.078055Z",
     "iopub.status.idle": "2024-12-04T18:27:23.072906Z",
     "shell.execute_reply": "2024-12-04T18:27:23.072253Z",
     "shell.execute_reply.started": "2024-12-04T18:27:19.078840Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.utils import make_grid\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import torch.nn.init as init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T20:40:21.667168Z",
     "iopub.status.busy": "2024-12-03T20:40:21.666813Z",
     "iopub.status.idle": "2024-12-03T20:40:22.648743Z",
     "shell.execute_reply": "2024-12-03T20:40:22.648045Z",
     "shell.execute_reply.started": "2024-12-03T20:40:21.667143Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset = CIFAR10(\"./data\", train=True, download=True, transform=transforms.Compose([transforms.RandomHorizontalFlip(), transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T20:40:22.649854Z",
     "iopub.status.busy": "2024-12-03T20:40:22.649572Z",
     "iopub.status.idle": "2024-12-03T20:40:22.654070Z",
     "shell.execute_reply": "2024-12-03T20:40:22.653242Z",
     "shell.execute_reply.started": "2024-12-03T20:40:22.649829Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-12-03T20:40:22.655874Z",
     "iopub.status.busy": "2024-12-03T20:40:22.655584Z",
     "iopub.status.idle": "2024-12-03T20:40:25.518152Z",
     "shell.execute_reply": "2024-12-03T20:40:25.516771Z",
     "shell.execute_reply.started": "2024-12-03T20:40:22.655849Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "N = [200, 20, 10, 8, 6, 4, 3, 2]\n",
    "n = 10\n",
    "for image, y in dataloader:\n",
    "    n -= 1\n",
    "    # x = (image * (N-1)).round().long().clamp(0, N-1) / (N-1)\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=len(N), figsize=(len(N)*2,4))\n",
    "    # ax[0].imshow(image[0].permute(1, 2, 0).numpy())\n",
    "    # ax[1].imshow(x[0].permute(1, 2, 0).numpy())\n",
    "    for i in range(len(ax)):\n",
    "        x = (image * (N[i]-1)).round().long().clamp(0, N[i]-1) / (N[i]-1)\n",
    "        ax[i].imshow(x[0].permute(1,2,0).numpy())\n",
    "        ax[i].axis('off')\n",
    "    plt.show()\n",
    "    if not n:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial POC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T18:28:36.952939Z",
     "iopub.status.busy": "2024-12-04T18:28:36.952561Z",
     "iopub.status.idle": "2024-12-04T18:28:36.989463Z",
     "shell.execute_reply": "2024-12-04T18:28:36.988784Z",
     "shell.execute_reply.started": "2024-12-04T18:28:36.952907Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import make_grid\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "\n",
    "blk = lambda ic, oc: nn.Sequential(\n",
    "    nn.Conv2d(ic, oc, 5, padding=2),\n",
    "    nn.GroupNorm(oc // 8, oc),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Conv2d(oc, oc, 5, padding=2),\n",
    "    nn.GroupNorm(oc // 8, oc),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Conv2d(oc, oc, 5, padding=2),\n",
    "    nn.GroupNorm(oc // 8, oc),\n",
    "    nn.LeakyReLU(),\n",
    ")\n",
    "\n",
    "blku = lambda ic, oc: nn.Sequential(\n",
    "    nn.Conv2d(ic, oc, 5, padding=2),\n",
    "    nn.GroupNorm(oc // 8, oc),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Conv2d(oc, oc, 5, padding=2),\n",
    "    nn.GroupNorm(oc // 8, oc),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Conv2d(oc, oc, 5, padding=2),\n",
    "    nn.GroupNorm(oc // 8, oc),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.ConvTranspose2d(oc, oc, 2, stride=2),\n",
    "    nn.GroupNorm(oc // 8, oc),\n",
    "    nn.LeakyReLU(),\n",
    ")\n",
    "\n",
    "\n",
    "class DummyX0Model_cond(nn.Module):\n",
    "\n",
    "    def __init__(self, n_channel: int, N: int = 16) -> None:\n",
    "        super(DummyX0Model_cond, self).__init__()\n",
    "        self.down1 = blk(n_channel, 16)\n",
    "        self.down2 = blk(16, 32)\n",
    "        self.down3 = blk(32, 64)\n",
    "        self.down4 = blk(64, 512)\n",
    "        self.down5 = blk(512, 512)\n",
    "        self.up1 = blku(512, 512)\n",
    "        self.up2 = blku(512 + 512, 64)\n",
    "        self.up3 = blku(64, 32)\n",
    "        self.up4 = blku(32, 16)\n",
    "        self.convlast = blk(16, 16)\n",
    "        self.final = nn.Conv2d(16, N * n_channel, 1, bias=False)\n",
    "\n",
    "        self.tr1 = nn.TransformerEncoderLayer(d_model=512, nhead=8)\n",
    "        self.tr2 = nn.TransformerEncoderLayer(d_model=512, nhead=8)\n",
    "        self.tr3 = nn.TransformerEncoderLayer(d_model=64, nhead=8)\n",
    "\n",
    "        self.cond_embedding_1 = nn.Embedding(10, 16)\n",
    "        self.cond_embedding_2 = nn.Embedding(10, 32)\n",
    "        self.cond_embedding_3 = nn.Embedding(10, 64)\n",
    "        self.cond_embedding_4 = nn.Embedding(10, 512)\n",
    "        self.cond_embedding_5 = nn.Embedding(10, 512)\n",
    "        self.cond_embedding_6 = nn.Embedding(10, 64)\n",
    "\n",
    "        self.temb_1 = nn.Linear(32, 16)\n",
    "        self.temb_2 = nn.Linear(32, 32)\n",
    "        self.temb_3 = nn.Linear(32, 64)\n",
    "        self.temb_4 = nn.Linear(32, 512)\n",
    "        self.N = N\n",
    "\n",
    "    def forward(self, x, t, cond) -> torch.Tensor:\n",
    "        x = (2 * x.float() / self.N) - 1.0\n",
    "        t = t.float().reshape(-1, 1) / 1000\n",
    "        t_features = [torch.sin(t * 3.1415 * 2**i) for i in range(16)] + [\n",
    "            torch.cos(t * 3.1415 * 2**i) for i in range(16)\n",
    "        ]\n",
    "        tx = torch.cat(t_features, dim=1).to(x.device)\n",
    "\n",
    "        t_emb_1 = self.temb_1(tx).unsqueeze(-1).unsqueeze(-1)\n",
    "        t_emb_2 = self.temb_2(tx).unsqueeze(-1).unsqueeze(-1)\n",
    "        t_emb_3 = self.temb_3(tx).unsqueeze(-1).unsqueeze(-1)\n",
    "        t_emb_4 = self.temb_4(tx).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        cond_emb_1 = self.cond_embedding_1(cond).unsqueeze(-1).unsqueeze(-1)\n",
    "        cond_emb_2 = self.cond_embedding_2(cond).unsqueeze(-1).unsqueeze(-1)\n",
    "        cond_emb_3 = self.cond_embedding_3(cond).unsqueeze(-1).unsqueeze(-1)\n",
    "        cond_emb_4 = self.cond_embedding_4(cond).unsqueeze(-1).unsqueeze(-1)\n",
    "        cond_emb_5 = self.cond_embedding_5(cond).unsqueeze(-1).unsqueeze(-1)\n",
    "        cond_emb_6 = self.cond_embedding_6(cond).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        x1 = self.down1(x) + t_emb_1 + cond_emb_1\n",
    "        x2 = self.down2(nn.functional.avg_pool2d(x1, 2)) + t_emb_2 + cond_emb_2\n",
    "        x3 = self.down3(nn.functional.avg_pool2d(x2, 2)) + t_emb_3 + cond_emb_3\n",
    "        x4 = self.down4(nn.functional.avg_pool2d(x3, 2)) + t_emb_4 + cond_emb_4\n",
    "        x5 = self.down5(nn.functional.avg_pool2d(x4, 2))\n",
    "\n",
    "        x5 = (\n",
    "            self.tr1(x5.reshape(x5.shape[0], x5.shape[1], -1).transpose(1, 2))\n",
    "            .transpose(1, 2)\n",
    "            .reshape(x5.shape)\n",
    "        )\n",
    "\n",
    "        y = self.up1(x5) + cond_emb_5\n",
    "\n",
    "        y = (\n",
    "            self.tr2(y.reshape(y.shape[0], y.shape[1], -1).transpose(1, 2))\n",
    "            .transpose(1, 2)\n",
    "            .reshape(y.shape)\n",
    "        )\n",
    "\n",
    "        y = self.up2(torch.cat([x4, y], dim=1)) + cond_emb_6\n",
    "\n",
    "        y = (\n",
    "            self.tr3(y.reshape(y.shape[0], y.shape[1], -1).transpose(1, 2))\n",
    "            .transpose(1, 2)\n",
    "            .reshape(y.shape)\n",
    "        )\n",
    "        y = self.up3(y)\n",
    "        y = self.up4(y)\n",
    "        y = self.convlast(y)\n",
    "        y = self.final(y)\n",
    "\n",
    "        # reshape to B, C, H, W, N\n",
    "        y = (\n",
    "            y.reshape(y.shape[0], -1, self.N, *x.shape[2:])\n",
    "            .transpose(2, -1)\n",
    "            .contiguous()\n",
    "        )\n",
    "\n",
    "        return y\n",
    "\n",
    "\n",
    "class D3PM_cond(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        x0_model: nn.Module,\n",
    "        n_T: int,\n",
    "        num_classes: int = 10,\n",
    "        forward_type=\"uniform\",\n",
    "        hybrid_loss_coeff=0.001,\n",
    "    ) -> None:\n",
    "        super(D3PM_cond, self).__init__()\n",
    "        self.x0_model = x0_model\n",
    "\n",
    "        self.n_T = n_T\n",
    "        self.hybrid_loss_coeff = hybrid_loss_coeff\n",
    "\n",
    "        steps = torch.arange(n_T + 1, dtype=torch.float64) / n_T\n",
    "        alpha_bar = torch.cos((steps + 0.008) / 1.008 * torch.pi / 2)\n",
    "        self.beta_t = torch.minimum(\n",
    "            1 - alpha_bar[1:] / alpha_bar[:-1], torch.ones_like(alpha_bar[1:]) * 0.999\n",
    "        )\n",
    "\n",
    "        # self.beta_t = [1 / (self.n_T - t + 1) for t in range(1, self.n_T + 1)]\n",
    "        self.eps = 1e-6\n",
    "        self.num_classses = num_classes\n",
    "        q_onestep_mats = []\n",
    "        q_mats = []  # these are cumulative\n",
    "\n",
    "        for beta in self.beta_t:\n",
    "\n",
    "            if forward_type == \"uniform\":\n",
    "                mat = torch.ones(num_classes, num_classes) * beta / num_classes\n",
    "                mat.diagonal().fill_(1 - (num_classes - 1) * beta / num_classes)\n",
    "                q_onestep_mats.append(mat)\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "        q_one_step_mats = torch.stack(q_onestep_mats, dim=0)\n",
    "\n",
    "        q_one_step_transposed = q_one_step_mats.transpose(\n",
    "            1, 2\n",
    "        )  # this will be used for q_posterior_logits\n",
    "\n",
    "        q_mat_t = q_onestep_mats[0]\n",
    "        q_mats = [q_mat_t]\n",
    "        for idx in range(1, self.n_T):\n",
    "            q_mat_t = q_mat_t @ q_onestep_mats[idx]\n",
    "            q_mats.append(q_mat_t)\n",
    "        q_mats = torch.stack(q_mats, dim=0)\n",
    "        self.logit_type = \"logit\"\n",
    "\n",
    "        # register\n",
    "        self.register_buffer(\"q_one_step_transposed\", q_one_step_transposed)\n",
    "        self.register_buffer(\"q_mats\", q_mats)\n",
    "\n",
    "        assert self.q_mats.shape == (\n",
    "            self.n_T,\n",
    "            num_classes,\n",
    "            num_classes,\n",
    "        ), self.q_mats.shape\n",
    "\n",
    "    def _at(self, a, t, x):\n",
    "        # t is 1-d, x is integer value of 0 to num_classes - 1\n",
    "        bs = t.shape[0]\n",
    "        t = t.reshape((bs, *[1] * (x.dim() - 1)))\n",
    "        # out[i, j, k, l, m] = a[t[i, j, k, l], x[i, j, k, l], m]\n",
    "        return a[t - 1, x, :]\n",
    "\n",
    "    def q_posterior_logits(self, x_0, x_t, t):\n",
    "        # if t == 1, this means we return the L_0 loss, so directly try to x_0 logits.\n",
    "        # otherwise, we return the L_{t-1} loss.\n",
    "        # Also, we never have t == 0.\n",
    "\n",
    "        # if x_0 is integer, we convert it to one-hot.\n",
    "        if x_0.dtype == torch.int64 or x_0.dtype == torch.int32:\n",
    "            x_0_logits = torch.log(\n",
    "                torch.nn.functional.one_hot(x_0, self.num_classses) + self.eps\n",
    "            )\n",
    "        else:\n",
    "            x_0_logits = x_0.clone()\n",
    "\n",
    "        # print(\n",
    "        #     f\"x_0_logits.shape: {x_0_logits.shape}, x_t.shape: {x_t.shape}\"\n",
    "        # )\n",
    "\n",
    "        # Here, we caclulate equation (3) of the paper. Note that the x_0 Q_t x_t^T is a normalizing constant, so we don't deal with that.\n",
    "\n",
    "        # fact1 is \"guess of x_{t-1}\" from x_t\n",
    "        # fact2 is \"guess of x_{t-1}\" from x_0\n",
    "\n",
    "        fact1 = self._at(self.q_one_step_transposed, t, x_t)\n",
    "\n",
    "        softmaxed = torch.softmax(x_0_logits, dim=-1)  # bs, ..., num_classes\n",
    "        qmats2 = self.q_mats[t - 2].to(dtype=softmaxed.dtype)\n",
    "        # bs, num_classes, num_classes\n",
    "        fact2 = torch.einsum(\"b...c,bcd->b...d\", softmaxed, qmats2)\n",
    "\n",
    "        out = torch.log(fact1 + self.eps) + torch.log(fact2 + self.eps)\n",
    "\n",
    "        t_broadcast = t.reshape((t.shape[0], *[1] * (x_t.dim())))\n",
    "\n",
    "        bc = torch.where(t_broadcast == 1, x_0_logits, out)\n",
    "\n",
    "        return bc\n",
    "\n",
    "    def vb(self, dist1, dist2):\n",
    "\n",
    "        # flatten dist1 and dist2\n",
    "        dist1 = dist1.flatten(start_dim=0, end_dim=-2)\n",
    "        dist2 = dist2.flatten(start_dim=0, end_dim=-2)\n",
    "\n",
    "        out = torch.softmax(dist1 + self.eps, dim=-1) * (\n",
    "            torch.log_softmax(dist1 + self.eps, dim=-1)\n",
    "            - torch.log_softmax(dist2 + self.eps, dim=-1)\n",
    "        )\n",
    "        return out.sum(dim=-1).mean()\n",
    "\n",
    "    def q_sample(self, x_0, t, noise):\n",
    "        # forward process, x_0 is the clean input.\n",
    "        logits = torch.log(self._at(self.q_mats, t, x_0) + self.eps)\n",
    "        noise = torch.clip(noise, self.eps, 1.0)\n",
    "        gumbel_noise = -torch.log(-torch.log(noise))\n",
    "        return torch.argmax(logits + gumbel_noise, dim=-1)\n",
    "\n",
    "    def model_predict(self, x_0, t, cond):\n",
    "        # this part exists because in general, manipulation of logits from model's logit\n",
    "        # so they are in form of x_0's logit might be independent to model choice.\n",
    "        # for example, you can convert 2 * N channel output of model output to logit via get_logits_from_logistic_pars\n",
    "        # they introduce at appendix A.8.\n",
    "\n",
    "        predicted_x0_logits = self.x0_model(x_0, t, cond)\n",
    "\n",
    "        return predicted_x0_logits\n",
    "\n",
    "    def forward(self, x: torch.Tensor, cond: torch.Tensor = None) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Makes forward diffusion x_t from x_0, and tries to guess x_0 value from x_t using x0_model.\n",
    "        x is one-hot of dim (bs, ...), with int values of 0 to num_classes - 1\n",
    "        \"\"\"\n",
    "        t = torch.randint(1, self.n_T, (x.shape[0],), device=x.device)\n",
    "        x_t = self.q_sample(\n",
    "            x, t, torch.rand((*x.shape, self.num_classses), device=x.device)\n",
    "        )\n",
    "        # x_t is same shape as x\n",
    "        # print(\n",
    "        #     f\"x_t.shape: {x_t.shape}, x.shape: {x.shape}\"\n",
    "        # )\n",
    "        # we use hybrid loss.\n",
    "\n",
    "        predicted_x0_logits = self.model_predict(x_t, t, cond)\n",
    "\n",
    "        # based on this, we first do vb loss.\n",
    "        true_q_posterior_logits = self.q_posterior_logits(x, x_t, t)\n",
    "        pred_q_posterior_logits = self.q_posterior_logits(predicted_x0_logits, x_t, t)\n",
    "\n",
    "        vb_loss = self.vb(true_q_posterior_logits, pred_q_posterior_logits)\n",
    "\n",
    "        predicted_x0_logits = predicted_x0_logits.flatten(start_dim=0, end_dim=-2)\n",
    "        x = x.flatten(start_dim=0, end_dim=-1)\n",
    "\n",
    "        ce_loss = torch.nn.CrossEntropyLoss()(predicted_x0_logits, x)\n",
    "\n",
    "        return self.hybrid_loss_coeff * vb_loss + ce_loss, {\n",
    "            \"vb_loss\": vb_loss.detach().item(),\n",
    "            \"ce_loss\": ce_loss.detach().item(),\n",
    "        }\n",
    "\n",
    "    def p_sample(self, x, t, cond, noise):\n",
    "\n",
    "        predicted_x0_logits = self.model_predict(x, t, cond)\n",
    "        pred_q_posterior_logits = self.q_posterior_logits(predicted_x0_logits, x, t)\n",
    "\n",
    "        noise = torch.clip(noise, self.eps, 1.0)\n",
    "\n",
    "        not_first_step = (t != 1).float().reshape((x.shape[0], *[1] * (x.dim())))\n",
    "\n",
    "        gumbel_noise = -torch.log(-torch.log(noise))\n",
    "        sample = torch.argmax(\n",
    "            pred_q_posterior_logits + gumbel_noise * not_first_step, dim=-1\n",
    "        )\n",
    "        return sample\n",
    "\n",
    "    def sample(self, x, cond=None):\n",
    "        for t in reversed(range(1, self.n_T)):\n",
    "            t = torch.tensor([t] * x.shape[0], device=x.device)\n",
    "            x = self.p_sample(\n",
    "                x, t, cond, torch.rand((*x.shape, self.num_classses), device=x.device)\n",
    "            )\n",
    "\n",
    "        return x\n",
    "\n",
    "    def sample_with_image_sequence(self, x, cond=None, stride=10):\n",
    "        steps = 0\n",
    "        images = []\n",
    "        for t in reversed(range(1, self.n_T)):\n",
    "            t = torch.tensor([t] * x.shape[0], device=x.device)\n",
    "            x = self.p_sample(\n",
    "                x, t, cond, torch.rand((*x.shape, self.num_classses), device=x.device)\n",
    "            )\n",
    "            steps += 1\n",
    "            if steps % stride == 0:\n",
    "                images.append(x)\n",
    "\n",
    "        # if last step is not divisible by stride, we add the last image.\n",
    "        if steps % stride != 0:\n",
    "            images.append(x)\n",
    "\n",
    "        return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T20:40:46.814779Z",
     "iopub.status.busy": "2024-12-03T20:40:46.814384Z",
     "iopub.status.idle": "2024-12-03T20:40:46.857468Z",
     "shell.execute_reply": "2024-12-03T20:40:46.856564Z",
     "shell.execute_reply.started": "2024-12-03T20:40:46.814702Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def modulate(x, shift, scale):\n",
    "    return x * (1 + scale.unsqueeze(1)) + shift.unsqueeze(1)\n",
    "\n",
    "\n",
    "class TimestepEmbedder(nn.Module):\n",
    "    def __init__(self, hidden_size, frequency_embedding_size=256):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(frequency_embedding_size, hidden_size),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "        )\n",
    "        self.frequency_embedding_size = frequency_embedding_size\n",
    "\n",
    "    @staticmethod\n",
    "    def timestep_embedding(t, dim, max_period=10000):\n",
    "        half = dim // 2\n",
    "        freqs = torch.exp(\n",
    "            -math.log(max_period) * torch.arange(start=0, end=half) / half\n",
    "        ).to(t.device)\n",
    "        args = t[:, None] * freqs[None]\n",
    "        embedding = torch.cat([torch.cos(args), torch.sin(args)], dim=-1)\n",
    "        if dim % 2:\n",
    "            embedding = torch.cat(\n",
    "                [embedding, torch.zeros_like(embedding[:, :1])], dim=-1\n",
    "            )\n",
    "        return embedding\n",
    "\n",
    "    def forward(self, t):\n",
    "        t_freq = self.timestep_embedding(t, self.frequency_embedding_size).to(\n",
    "            dtype=next(self.parameters()).dtype\n",
    "        )\n",
    "        t_emb = self.mlp(t_freq)\n",
    "        return t_emb\n",
    "\n",
    "\n",
    "class LabelEmbedder(nn.Module):\n",
    "    def __init__(self, num_classes, hidden_size, dropout_prob):\n",
    "        super().__init__()\n",
    "        use_cfg_embedding = int(dropout_prob > 0)\n",
    "        self.embedding_table = nn.Embedding(\n",
    "            num_classes + use_cfg_embedding, hidden_size\n",
    "        )\n",
    "        self.num_classes = num_classes\n",
    "        self.dropout_prob = dropout_prob\n",
    "\n",
    "    def token_drop(self, labels, force_drop_ids=None):\n",
    "        if force_drop_ids is None:\n",
    "            drop_ids = torch.rand(labels.shape[0]) < self.dropout_prob\n",
    "            drop_ids = drop_ids.cuda()\n",
    "            drop_ids = drop_ids.to(labels.device)\n",
    "        else:\n",
    "            drop_ids = force_drop_ids == 1\n",
    "        labels = torch.where(drop_ids, self.num_classes, labels)\n",
    "        return labels\n",
    "\n",
    "    def forward(self, labels, train, force_drop_ids=None):\n",
    "        use_dropout = self.dropout_prob > 0\n",
    "        if (train and use_dropout) or (force_drop_ids is not None):\n",
    "            labels = self.token_drop(labels, force_drop_ids)\n",
    "        embeddings = self.embedding_table(labels)\n",
    "        return embeddings\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, n_heads):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_heads = n_heads\n",
    "        self.n_rep = 1\n",
    "        self.head_dim = dim // n_heads\n",
    "\n",
    "        self.wq = nn.Linear(dim, n_heads * self.head_dim, bias=False)\n",
    "        self.wk = nn.Linear(dim, self.n_heads * self.head_dim, bias=False)\n",
    "        self.wv = nn.Linear(dim, self.n_heads * self.head_dim, bias=False)\n",
    "        self.wo = nn.Linear(n_heads * self.head_dim, dim, bias=False)\n",
    "\n",
    "        self.q_norm = nn.LayerNorm(self.n_heads * self.head_dim)\n",
    "        self.k_norm = nn.LayerNorm(self.n_heads * self.head_dim)\n",
    "\n",
    "    @staticmethod\n",
    "    def reshape_for_broadcast(freqs_cis, x):\n",
    "        ndim = x.ndim\n",
    "        assert 0 <= 1 < ndim\n",
    "        assert freqs_cis.shape == (x.shape[1], x.shape[-1])\n",
    "        shape = [d if i == 1 or i == ndim - 1 else 1 for i, d in enumerate(x.shape)]\n",
    "        return freqs_cis.view(*shape)\n",
    "\n",
    "    @staticmethod\n",
    "    def apply_rotary_emb(xq, xk, freqs_cis):\n",
    "        xq_ = torch.view_as_complex(xq.float().reshape(*xq.shape[:-1], -1, 2))\n",
    "        xk_ = torch.view_as_complex(xk.float().reshape(*xk.shape[:-1], -1, 2))\n",
    "        freqs_cis = Attention.reshape_for_broadcast(freqs_cis, xq_)\n",
    "        xq_out = torch.view_as_real(xq_ * freqs_cis).flatten(3)\n",
    "        xk_out = torch.view_as_real(xk_ * freqs_cis).flatten(3)\n",
    "        return xq_out, xk_out\n",
    "\n",
    "    def forward(self, x, freqs_cis):\n",
    "        bsz, seqlen, _ = x.shape\n",
    "        xq, xk, xv = self.wq(x), self.wk(x), self.wv(x)\n",
    "        dtype = xq.dtype\n",
    "\n",
    "        xq = self.q_norm(xq)\n",
    "        xk = self.k_norm(xk)\n",
    "\n",
    "        xq = xq.view(bsz, seqlen, self.n_heads, self.head_dim)\n",
    "        xk = xk.view(bsz, seqlen, self.n_heads, self.head_dim)\n",
    "        xv = xv.view(bsz, seqlen, self.n_heads, self.head_dim)\n",
    "\n",
    "        xq, xk = self.apply_rotary_emb(xq, xk, freqs_cis=freqs_cis)\n",
    "        xq, xk = xq.to(dtype), xk.to(dtype)\n",
    "\n",
    "        output = F.scaled_dot_product_attention(\n",
    "            xq.permute(0, 2, 1, 3),\n",
    "            xk.permute(0, 2, 1, 3),\n",
    "            xv.permute(0, 2, 1, 3),\n",
    "            dropout_p=0.0,\n",
    "            is_causal=False,\n",
    "        ).permute(0, 2, 1, 3)\n",
    "        output = output.flatten(-2)\n",
    "\n",
    "        return self.wo(output)\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim, multiple_of, ffn_dim_multiplier=None):\n",
    "        super().__init__()\n",
    "        hidden_dim = int(2 * hidden_dim / 3)\n",
    "        if ffn_dim_multiplier:\n",
    "            hidden_dim = int(ffn_dim_multiplier * hidden_dim)\n",
    "        hidden_dim = multiple_of * ((hidden_dim + multiple_of - 1) // multiple_of)\n",
    "\n",
    "        self.w1 = nn.Linear(dim, hidden_dim, bias=False)\n",
    "        self.w2 = nn.Linear(hidden_dim, dim, bias=False)\n",
    "        self.w3 = nn.Linear(dim, hidden_dim, bias=False)\n",
    "\n",
    "    def _forward_silu_gating(self, x1, x3):\n",
    "        return F.silu(x1) * x3\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w2(self._forward_silu_gating(self.w1(x), self.w3(x)))\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        layer_id,\n",
    "        dim,\n",
    "        n_heads,\n",
    "        multiple_of,\n",
    "        ffn_dim_multiplier,\n",
    "        norm_eps,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.head_dim = dim // n_heads\n",
    "        self.attention = Attention(dim, n_heads)\n",
    "        self.feed_forward = FeedForward(\n",
    "            dim=dim,\n",
    "            hidden_dim=4 * dim,\n",
    "            multiple_of=multiple_of,\n",
    "            ffn_dim_multiplier=ffn_dim_multiplier,\n",
    "        )\n",
    "        self.layer_id = layer_id\n",
    "        self.attention_norm = nn.LayerNorm(dim, eps=norm_eps)\n",
    "        self.ffn_norm = nn.LayerNorm(dim, eps=norm_eps)\n",
    "\n",
    "        self.adaLN_modulation = nn.Sequential(\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(min(dim, 1024), 6 * dim, bias=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, freqs_cis, adaln_input=None):\n",
    "        if adaln_input is not None:\n",
    "            shift_msa, scale_msa, gate_msa, shift_mlp, scale_mlp, gate_mlp = (\n",
    "                self.adaLN_modulation(adaln_input).chunk(6, dim=1)\n",
    "            )\n",
    "\n",
    "            x = x + gate_msa.unsqueeze(1) * self.attention(\n",
    "                modulate(self.attention_norm(x), shift_msa, scale_msa), freqs_cis\n",
    "            )\n",
    "            x = x + gate_mlp.unsqueeze(1) * self.feed_forward(\n",
    "                modulate(self.ffn_norm(x), shift_mlp, scale_mlp)\n",
    "            )\n",
    "        else:\n",
    "            x = x + self.attention(self.attention_norm(x), freqs_cis)\n",
    "            x = x + self.feed_forward(self.ffn_norm(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class FinalLayer(nn.Module):\n",
    "    def __init__(self, hidden_size, patch_size, out_channels):\n",
    "        super().__init__()\n",
    "        self.norm_final = nn.LayerNorm(hidden_size, elementwise_affine=False, eps=1e-6)\n",
    "        self.linear = nn.Linear(\n",
    "            hidden_size, patch_size * patch_size * out_channels, bias=True\n",
    "        )\n",
    "        self.adaLN_modulation = nn.Sequential(\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(min(hidden_size, 1024), 2 * hidden_size, bias=True),\n",
    "        )\n",
    "        # # init zero\n",
    "        nn.init.constant_(self.linear.weight, 0)\n",
    "        nn.init.constant_(self.linear.bias, 0)\n",
    "\n",
    "    def forward(self, x, c):\n",
    "        shift, scale = self.adaLN_modulation(c).chunk(2, dim=1)\n",
    "        x = modulate(self.norm_final(x), shift, scale)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DDiT_Llama(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        N=256,\n",
    "        dim=512,\n",
    "        n_layers=5,\n",
    "        n_heads=16,\n",
    "        multiple_of=256,\n",
    "        ffn_dim_multiplier=None,\n",
    "        norm_eps=1e-5,\n",
    "        learn_gating=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.N = N\n",
    "        self.learn_gating = learn_gating\n",
    "        if self.learn_gating:\n",
    "            self.out_channel = N * 2\n",
    "        else:\n",
    "            self.out_channel = N\n",
    "\n",
    "        self.embedder = nn.Embedding(N, dim)\n",
    "        self.t_embedder = TimestepEmbedder(min(dim, 1024))\n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                TransformerBlock(\n",
    "                    layer_id,\n",
    "                    dim,\n",
    "                    n_heads,\n",
    "                    multiple_of,\n",
    "                    ffn_dim_multiplier,\n",
    "                    norm_eps,\n",
    "                )\n",
    "                for layer_id in range(n_layers)\n",
    "            ]\n",
    "        )\n",
    "        self.final_layer = FinalLayer(dim, 1, self.out_channel)\n",
    "        self.freqs_cis = DiT_Llama.precompute_freqs_cis(dim // n_heads, 4096)\n",
    "\n",
    "    def forward(self, x, t, cond=None):\n",
    "        self.freqs_cis = self.freqs_cis.to(x.device)\n",
    "        x_onehot = torch.nn.functional.one_hot(x, self.N).to(\n",
    "            x.device, dtype=next(self.parameters()).dtype\n",
    "        )\n",
    "        x = self.embedder(x)\n",
    "        adaln_input = self.t_embedder(t)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, self.freqs_cis[: x.size(1)], adaln_input=adaln_input)\n",
    "\n",
    "        x = self.final_layer(x, adaln_input)\n",
    "        if self.learn_gating:\n",
    "            x, gate = x.chunk(2, dim=-1)\n",
    "            return x + x_onehot * (1 + gate).abs()\n",
    "        else:\n",
    "            return x + x_onehot\n",
    "\n",
    "\n",
    "class DiT_Llama(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels=3,\n",
    "        N=8,\n",
    "        input_size=32,\n",
    "        patch_size=2,\n",
    "        dim=512,\n",
    "        n_layers=5,\n",
    "        n_heads=16,\n",
    "        multiple_of=256,\n",
    "        ffn_dim_multiplier=None,\n",
    "        norm_eps=1e-5,\n",
    "        class_dropout_prob=0.1,\n",
    "        num_classes=10,\n",
    "        learn_sigma=True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.N = N\n",
    "        self.learn_sigma = learn_sigma\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = N * in_channels * 2\n",
    "        self.input_size = input_size\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "        self.init_conv_seq = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, dim // 2, kernel_size=5, padding=2, stride=1),\n",
    "            nn.SiLU(),\n",
    "            nn.GroupNorm(32, dim // 2),\n",
    "            nn.Conv2d(dim // 2, dim // 2, kernel_size=5, padding=2, stride=1),\n",
    "            nn.SiLU(),\n",
    "            nn.GroupNorm(32, dim // 2),\n",
    "        )\n",
    "\n",
    "        self.x_embedder = nn.Linear(patch_size * patch_size * dim // 2, dim, bias=True)\n",
    "        nn.init.constant_(self.x_embedder.bias, 0)\n",
    "\n",
    "        self.t_embedder = TimestepEmbedder(min(dim, 1024))\n",
    "        self.y_embedder = LabelEmbedder(num_classes, min(dim, 1024), class_dropout_prob)\n",
    "\n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                TransformerBlock(\n",
    "                    layer_id,\n",
    "                    dim,\n",
    "                    n_heads,\n",
    "                    multiple_of,\n",
    "                    ffn_dim_multiplier,\n",
    "                    norm_eps,\n",
    "                )\n",
    "                for layer_id in range(n_layers)\n",
    "            ]\n",
    "        )\n",
    "        self.final_layer = FinalLayer(dim, patch_size, self.out_channels)\n",
    "\n",
    "        self.freqs_cis = DiT_Llama.precompute_freqs_cis(dim // n_heads, 4096)\n",
    "\n",
    "    def unpatchify(self, x):\n",
    "        c = self.out_channels\n",
    "        p = self.patch_size\n",
    "        h = w = int(x.shape[1] ** 0.5)\n",
    "        x = x.reshape(shape=(x.shape[0], h, w, p, p, c))\n",
    "        x = torch.einsum(\"nhwpqc->nchpwq\", x)\n",
    "        imgs = x.reshape(shape=(x.shape[0], c, h * p, h * p))\n",
    "        return imgs\n",
    "\n",
    "    def patchify(self, x):\n",
    "        B, C, H, W = x.size()\n",
    "        x = x.view(\n",
    "            B,\n",
    "            C,\n",
    "            H // self.patch_size,\n",
    "            self.patch_size,\n",
    "            W // self.patch_size,\n",
    "            self.patch_size,\n",
    "        )\n",
    "        x = x.permute(0, 2, 4, 1, 3, 5).flatten(-3).flatten(1, 2)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x, t, y):\n",
    "        self.freqs_cis = self.freqs_cis.to(x.device)\n",
    "\n",
    "        x_onehot = torch.nn.functional.one_hot(x, self.N).float().to(x.device)\n",
    "        x = (2 * x.float() / (self.N - 1)) - 1.0\n",
    "        x = self.init_conv_seq(x)\n",
    "\n",
    "        x = self.patchify(x)\n",
    "        x = self.x_embedder(x)\n",
    "\n",
    "        t = self.t_embedder(t)  # (N, D)\n",
    "        y = self.y_embedder(y, self.training)  # (N, D)\n",
    "        adaln_input = t + y\n",
    "\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, self.freqs_cis[: x.size(1)], adaln_input=adaln_input)\n",
    "\n",
    "        x = self.final_layer(x, adaln_input)\n",
    "        x = self.unpatchify(x)  # (N, out_channels, H, W)\n",
    "\n",
    "        x, gate = (\n",
    "            x.reshape(x.shape[0], -1, self.N * 2, *x.shape[2:])\n",
    "            .transpose(2, -1)\n",
    "            .contiguous()\n",
    "        ).chunk(2, dim=-1)\n",
    "\n",
    "        return x + x_onehot * (1 + gate).abs()\n",
    "\n",
    "        # x = (x.reshape(x.shape[0], -1, self.N, *x.shape[2:])\n",
    "        #     .transpose(2, -1)\n",
    "        #     .contiguous()\n",
    "        # )\n",
    "        # return x\n",
    "\n",
    "    def forward_with_cfg(self, x, t, y, cfg_scale):\n",
    "        half = x[: len(x) // 2]\n",
    "        combined = torch.cat([half, half], dim=0)\n",
    "        model_out = self.forward(combined, t, y)\n",
    "        eps, rest = model_out[:, : self.in_channels], model_out[:, self.in_channels :]\n",
    "        cond_eps, uncond_eps = torch.split(eps, len(eps) // 2, dim=0)\n",
    "        half_eps = uncond_eps + cfg_scale * (cond_eps - uncond_eps)\n",
    "        eps = torch.cat([half_eps, half_eps], dim=0)\n",
    "        return torch.cat([eps, rest], dim=1)\n",
    "\n",
    "    @staticmethod\n",
    "    def precompute_freqs_cis(dim, end, theta=10000.0):\n",
    "        freqs = 1.0 / (theta ** (torch.arange(0, dim, 2)[: (dim // 2)].float() / dim))\n",
    "        t = torch.arange(end)\n",
    "        freqs = torch.outer(t, freqs).float()\n",
    "        freqs_cis = torch.polar(torch.ones_like(freqs), freqs)\n",
    "        return freqs_cis\n",
    "\n",
    "\n",
    "def DiT_Llama_600M_patch2(**kwargs):\n",
    "    return DiT_Llama(patch_size=2, dim=256, n_layers=16, n_heads=32, **kwargs)\n",
    "\n",
    "\n",
    "def DiT_Llama_3B_patch2(**kwargs):\n",
    "    return DiT_Llama(patch_size=2, dim=3072, n_layers=32, n_heads=32, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T08:06:07.973181Z",
     "iopub.status.busy": "2024-12-04T08:06:07.972409Z",
     "iopub.status.idle": "2024-12-04T08:06:14.937974Z",
     "shell.execute_reply": "2024-12-04T08:06:14.936009Z",
     "shell.execute_reply.started": "2024-12-04T08:06:07.973149Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    import os\n",
    "    if not os.path.exists('contents'):\n",
    "        os.makedirs('contents')\n",
    "\n",
    "    N = 2  # number of classes for discretized state per pixel\n",
    "    d3pm = D3PM_cond(DummyX0Model_cond(1, N), 1000, num_classes=N, hybrid_loss_coeff=0.0).cuda()\n",
    "    print(f\"Total Param Count: {sum([p.numel() for p in d3pm.x0_model.parameters()])}\")\n",
    "    dataset = MNIST(\n",
    "        \"./data\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Pad(2),\n",
    "            ]\n",
    "        ),\n",
    "    )\n",
    "    dataloader = DataLoader(dataset, batch_size=256, shuffle=True, num_workers=32)\n",
    "\n",
    "    optim = torch.optim.AdamW(d3pm.x0_model.parameters(), lr=1e-3)\n",
    "    d3pm.train()\n",
    "\n",
    "    n_epoch = 400\n",
    "    device = \"cuda\"\n",
    "\n",
    "    global_step = 0\n",
    "    for i in range(n_epoch):\n",
    "\n",
    "        pbar = tqdm(dataloader)\n",
    "        loss_ema = None\n",
    "        for x, cond in pbar:\n",
    "            optim.zero_grad()\n",
    "            x = x.to(device)\n",
    "            cond = cond.to(device)\n",
    "\n",
    "            # discritize x to N bins\n",
    "            x = (x * (N - 1)).round().long().clamp(0, N - 1)\n",
    "            loss, info = d3pm(x, cond)\n",
    "\n",
    "            loss.backward()\n",
    "            norm = torch.nn.utils.clip_grad_norm_(d3pm.x0_model.parameters(), 0.1)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                param_norm = sum([torch.norm(p) for p in d3pm.x0_model.parameters()])\n",
    "\n",
    "            if loss_ema is None:\n",
    "                loss_ema = loss.item()\n",
    "            else:\n",
    "                loss_ema = 0.99 * loss_ema + 0.01 * loss.item()\n",
    "            pbar.set_description(\n",
    "                f\"loss: {loss_ema:.4f}, norm: {norm:.4f}, param_norm: {param_norm:.4f}, vb_loss: {info['vb_loss']:.4f}, ce_loss: {info['ce_loss']:.4f}\"\n",
    "            )\n",
    "            optim.step()\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % 300 == 1:\n",
    "                d3pm.eval()\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    cond = torch.arange(0, 4).cuda() % 10\n",
    "                    init_noise = torch.randint(0, N, (4, 1, 32, 32)).cuda()\n",
    "\n",
    "                    images = d3pm.sample_with_image_sequence(\n",
    "                        init_noise, cond, stride=40\n",
    "                    )\n",
    "                    # image sequences to gif\n",
    "                    gif = []\n",
    "                    for image in images:\n",
    "                        x_as_image = make_grid(image.float() / (N - 1), nrow=2)\n",
    "                        img = x_as_image.permute(1, 2, 0).cpu().numpy()\n",
    "                        img = (img * 255).astype(np.uint8)\n",
    "                        gif.append(Image.fromarray(img))\n",
    "\n",
    "                    gif[0].save(\n",
    "                        f\"contents/sample_{global_step}.gif\",\n",
    "                        save_all=True,\n",
    "                        append_images=gif[1:],\n",
    "                        duration=100,\n",
    "                        loop=0,\n",
    "                    )\n",
    "\n",
    "                    last_img = gif[-1]\n",
    "                    last_img.save(f\"contents/sample_{global_step}_last.png\")\n",
    "\n",
    "                d3pm.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T20:58:54.567373Z",
     "iopub.status.busy": "2024-12-03T20:58:54.566770Z",
     "iopub.status.idle": "2024-12-03T20:58:54.718762Z",
     "shell.execute_reply": "2024-12-03T20:58:54.717786Z",
     "shell.execute_reply.started": "2024-12-03T20:58:54.567339Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(mpimg.imread('/kaggle/working/contents/sample_1501_last.png'))\n",
    "plt.title('Conditional Generation on MNIST')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unconditional on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T18:28:41.546261Z",
     "iopub.status.busy": "2024-12-04T18:28:41.545915Z",
     "iopub.status.idle": "2024-12-04T18:28:41.575706Z",
     "shell.execute_reply": "2024-12-04T18:28:41.574776Z",
     "shell.execute_reply.started": "2024-12-04T18:28:41.546229Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class DummyX0Model(nn.Module):\n",
    "\n",
    "    def __init__(self, n_channel: int, N: int = 16) -> None:\n",
    "        super(DummyX0Model, self).__init__()\n",
    "        self.down1 = blk(n_channel, 16)\n",
    "        self.down2 = blk(16, 32)\n",
    "        self.down3 = blk(32, 64)\n",
    "        self.down4 = blk(64, 512)\n",
    "        self.down5 = blk(512, 512)\n",
    "        self.up1 = blku(512, 512)\n",
    "        self.up2 = blku(512 + 512, 64)\n",
    "        self.up3 = blku(64, 32)\n",
    "        self.up4 = blku(32, 16)\n",
    "        self.convlast = blk(16, 16)\n",
    "        self.final = nn.Conv2d(16, N * n_channel, 1, bias=False)\n",
    "\n",
    "        self.tr1 = nn.TransformerEncoderLayer(d_model=512, nhead=8)\n",
    "        self.tr2 = nn.TransformerEncoderLayer(d_model=512, nhead=8)\n",
    "        self.tr3 = nn.TransformerEncoderLayer(d_model=64, nhead=8)\n",
    "\n",
    "        self.temb_1 = nn.Linear(32, 16)\n",
    "        self.temb_2 = nn.Linear(32, 32)\n",
    "        self.temb_3 = nn.Linear(32, 64)\n",
    "        self.temb_4 = nn.Linear(32, 512)\n",
    "        self.N = N\n",
    "\n",
    "    def forward(self, x, t) -> torch.Tensor:\n",
    "        x = (2 * x.float() / self.N) - 1.0\n",
    "        t = t.float().reshape(-1, 1) / 1000\n",
    "        t_features = [torch.sin(t * 3.1415 * 2**i) for i in range(16)] + [\n",
    "            torch.cos(t * 3.1415 * 2**i) for i in range(16)\n",
    "        ]\n",
    "        tx = torch.cat(t_features, dim=1).to(x.device)\n",
    "\n",
    "        t_emb_1 = self.temb_1(tx).unsqueeze(-1).unsqueeze(-1)\n",
    "        t_emb_2 = self.temb_2(tx).unsqueeze(-1).unsqueeze(-1)\n",
    "        t_emb_3 = self.temb_3(tx).unsqueeze(-1).unsqueeze(-1)\n",
    "        t_emb_4 = self.temb_4(tx).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        x1 = self.down1(x) + t_emb_1\n",
    "        x2 = self.down2(nn.functional.avg_pool2d(x1, 2)) + t_emb_2\n",
    "        x3 = self.down3(nn.functional.avg_pool2d(x2, 2)) + t_emb_3\n",
    "        x4 = self.down4(nn.functional.avg_pool2d(x3, 2)) + t_emb_4 \n",
    "        x5 = self.down5(nn.functional.avg_pool2d(x4, 2))\n",
    "\n",
    "        x5 = (\n",
    "            self.tr1(x5.reshape(x5.shape[0], x5.shape[1], -1).transpose(1, 2))\n",
    "            .transpose(1, 2)\n",
    "            .reshape(x5.shape)\n",
    "        )\n",
    "\n",
    "        y = self.up1(x5)\n",
    "\n",
    "        y = (\n",
    "            self.tr2(y.reshape(y.shape[0], y.shape[1], -1).transpose(1, 2))\n",
    "            .transpose(1, 2)\n",
    "            .reshape(y.shape)\n",
    "        )\n",
    "\n",
    "        y = self.up2(torch.cat([x4, y], dim=1))\n",
    "\n",
    "        y = (\n",
    "            self.tr3(y.reshape(y.shape[0], y.shape[1], -1).transpose(1, 2))\n",
    "            .transpose(1, 2)\n",
    "            .reshape(y.shape)\n",
    "        )\n",
    "        y = self.up3(y)\n",
    "        y = self.up4(y)\n",
    "        y = self.convlast(y)\n",
    "        y = self.final(y)\n",
    "\n",
    "        # reshape to B, C, H, W, N\n",
    "        y = (\n",
    "            y.reshape(y.shape[0], -1, self.N, *x.shape[2:])\n",
    "            .transpose(2, -1)\n",
    "            .contiguous()\n",
    "        )\n",
    "\n",
    "        return y\n",
    "\n",
    "\n",
    "class D3PM(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        x0_model: nn.Module,\n",
    "        n_T: int,\n",
    "        num_classes: int = 10,\n",
    "        forward_type=\"uniform\",\n",
    "        hybrid_loss_coeff=0.001,\n",
    "    ) -> None:\n",
    "        super(D3PM, self).__init__()\n",
    "        self.x0_model = x0_model\n",
    "\n",
    "        self.n_T = n_T\n",
    "        self.hybrid_loss_coeff = hybrid_loss_coeff\n",
    "\n",
    "        steps = torch.arange(n_T + 1, dtype=torch.float64) / n_T\n",
    "        alpha_bar = torch.cos((steps + 0.008) / 1.008 * torch.pi / 2)\n",
    "        self.beta_t = torch.minimum(\n",
    "            1 - alpha_bar[1:] / alpha_bar[:-1], torch.ones_like(alpha_bar[1:]) * 0.999\n",
    "        )\n",
    "\n",
    "        # self.beta_t = [1 / (self.n_T - t + 1) for t in range(1, self.n_T + 1)]\n",
    "        self.eps = 1e-6\n",
    "        self.num_classses = num_classes\n",
    "        q_onestep_mats = []\n",
    "        q_mats = []  # these are cumulative\n",
    "\n",
    "        for beta in self.beta_t:\n",
    "\n",
    "            if forward_type == \"uniform\":\n",
    "                mat = torch.ones(num_classes, num_classes) * beta / num_classes\n",
    "                mat.diagonal().fill_(1 - (num_classes - 1) * beta / num_classes)\n",
    "                q_onestep_mats.append(mat)\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "        q_one_step_mats = torch.stack(q_onestep_mats, dim=0)\n",
    "\n",
    "        q_one_step_transposed = q_one_step_mats.transpose(\n",
    "            1, 2\n",
    "        )  # this will be used for q_posterior_logits\n",
    "\n",
    "        q_mat_t = q_onestep_mats[0]\n",
    "        q_mats = [q_mat_t]\n",
    "        for idx in range(1, self.n_T):\n",
    "            q_mat_t = q_mat_t @ q_onestep_mats[idx]\n",
    "            q_mats.append(q_mat_t)\n",
    "        q_mats = torch.stack(q_mats, dim=0)\n",
    "        self.logit_type = \"logit\"\n",
    "\n",
    "        # register\n",
    "        self.register_buffer(\"q_one_step_transposed\", q_one_step_transposed)\n",
    "        self.register_buffer(\"q_mats\", q_mats)\n",
    "\n",
    "        assert self.q_mats.shape == (\n",
    "            self.n_T,\n",
    "            num_classes,\n",
    "            num_classes,\n",
    "        ), self.q_mats.shape\n",
    "\n",
    "    def _at(self, a, t, x):\n",
    "        # t is 1-d, x is integer value of 0 to num_classes - 1\n",
    "        bs = t.shape[0]\n",
    "        t = t.reshape((bs, *[1] * (x.dim() - 1)))\n",
    "        # out[i, j, k, l, m] = a[t[i, j, k, l], x[i, j, k, l], m]\n",
    "        return a[t - 1, x, :]\n",
    "\n",
    "    def q_posterior_logits(self, x_0, x_t, t):\n",
    "        # if t == 1, this means we return the L_0 loss, so directly try to x_0 logits.\n",
    "        # otherwise, we return the L_{t-1} loss.\n",
    "        # Also, we never have t == 0.\n",
    "\n",
    "        # if x_0 is integer, we convert it to one-hot.\n",
    "        if x_0.dtype == torch.int64 or x_0.dtype == torch.int32:\n",
    "            x_0_logits = torch.log(\n",
    "                torch.nn.functional.one_hot(x_0, self.num_classses) + self.eps\n",
    "            )\n",
    "        else:\n",
    "            x_0_logits = x_0.clone()\n",
    "\n",
    "        # print(\n",
    "        #     f\"x_0_logits.shape: {x_0_logits.shape}, x_t.shape: {x_t.shape}\"\n",
    "        # )\n",
    "\n",
    "        # Here, we caclulate equation (3) of the paper. Note that the x_0 Q_t x_t^T is a normalizing constant, so we don't deal with that.\n",
    "\n",
    "        # fact1 is \"guess of x_{t-1}\" from x_t\n",
    "        # fact2 is \"guess of x_{t-1}\" from x_0\n",
    "\n",
    "        fact1 = self._at(self.q_one_step_transposed, t, x_t)\n",
    "\n",
    "        softmaxed = torch.softmax(x_0_logits, dim=-1)  # bs, ..., num_classes\n",
    "        qmats2 = self.q_mats[t - 2].to(dtype=softmaxed.dtype)\n",
    "        # bs, num_classes, num_classes\n",
    "        fact2 = torch.einsum(\"b...c,bcd->b...d\", softmaxed, qmats2)\n",
    "\n",
    "        out = torch.log(fact1 + self.eps) + torch.log(fact2 + self.eps)\n",
    "\n",
    "        t_broadcast = t.reshape((t.shape[0], *[1] * (x_t.dim())))\n",
    "\n",
    "        bc = torch.where(t_broadcast == 1, x_0_logits, out)\n",
    "\n",
    "        return bc\n",
    "\n",
    "    def vb(self, dist1, dist2):\n",
    "\n",
    "        # flatten dist1 and dist2\n",
    "        dist1 = dist1.flatten(start_dim=0, end_dim=-2)\n",
    "        dist2 = dist2.flatten(start_dim=0, end_dim=-2)\n",
    "\n",
    "        out = torch.softmax(dist1 + self.eps, dim=-1) * (\n",
    "            torch.log_softmax(dist1 + self.eps, dim=-1)\n",
    "            - torch.log_softmax(dist2 + self.eps, dim=-1)\n",
    "        )\n",
    "        return out.sum(dim=-1).mean()\n",
    "\n",
    "    def q_sample(self, x_0, t, noise):\n",
    "        # forward process, x_0 is the clean input.\n",
    "        logits = torch.log(self._at(self.q_mats, t, x_0) + self.eps)\n",
    "        noise = torch.clip(noise, self.eps, 1.0)\n",
    "        gumbel_noise = -torch.log(-torch.log(noise))\n",
    "        return torch.argmax(logits + gumbel_noise, dim=-1)\n",
    "\n",
    "    def model_predict(self, x_0, t):\n",
    "        # this part exists because in general, manipulation of logits from model's logit\n",
    "        # so they are in form of x_0's logit might be independent to model choice.\n",
    "        # for example, you can convert 2 * N channel output of model output to logit via get_logits_from_logistic_pars\n",
    "        # they introduce at appendix A.8.\n",
    "\n",
    "        predicted_x0_logits = self.x0_model(x_0, t)\n",
    "\n",
    "        return predicted_x0_logits\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Makes forward diffusion x_t from x_0, and tries to guess x_0 value from x_t using x0_model.\n",
    "        x is one-hot of dim (bs, ...), with int values of 0 to num_classes - 1\n",
    "        \"\"\"\n",
    "        t = torch.randint(1, self.n_T, (x.shape[0],), device=x.device)\n",
    "        x_t = self.q_sample(\n",
    "            x, t, torch.rand((*x.shape, self.num_classses), device=x.device)\n",
    "        )\n",
    "        # x_t is same shape as x\n",
    "        assert x_t.shape == x.shape, f\"x_t.shape: {x_t.shape}, x.shape: {x.shape}\"\n",
    "        # we use hybrid loss.\n",
    "        # print(x_t.shape)\n",
    "        predicted_x0_logits = self.model_predict(x_t, t)\n",
    "\n",
    "        # based on this, we first do vb loss.\n",
    "        true_q_posterior_logits = self.q_posterior_logits(x, x_t, t)\n",
    "        pred_q_posterior_logits = self.q_posterior_logits(predicted_x0_logits, x_t, t)\n",
    "\n",
    "        vb_loss = self.vb(true_q_posterior_logits, pred_q_posterior_logits)\n",
    "\n",
    "        predicted_x0_logits = predicted_x0_logits.flatten(start_dim=0, end_dim=-2)\n",
    "        x = x.flatten(start_dim=0, end_dim=-1)\n",
    "\n",
    "        ce_loss = torch.nn.CrossEntropyLoss()(predicted_x0_logits, x)\n",
    "\n",
    "        return self.hybrid_loss_coeff * vb_loss + ce_loss, {\n",
    "            \"vb_loss\": vb_loss.detach().item(),\n",
    "            \"ce_loss\": ce_loss.detach().item(),\n",
    "        }\n",
    "\n",
    "    def p_sample(self, x, t, noise):\n",
    "\n",
    "        predicted_x0_logits = self.model_predict(x, t)\n",
    "        pred_q_posterior_logits = self.q_posterior_logits(predicted_x0_logits, x, t)\n",
    "\n",
    "        noise = torch.clip(noise, self.eps, 1.0)\n",
    "\n",
    "        not_first_step = (t != 1).float().reshape((x.shape[0], *[1] * (x.dim())))\n",
    "\n",
    "        gumbel_noise = -torch.log(-torch.log(noise))\n",
    "        sample = torch.argmax(\n",
    "            pred_q_posterior_logits + gumbel_noise * not_first_step, dim=-1\n",
    "        )\n",
    "        return sample\n",
    "\n",
    "    def sample(self, x):\n",
    "        for t in reversed(range(1, self.n_T)):\n",
    "            t = torch.tensor([t] * x.shape[0], device=x.device)\n",
    "            x = self.p_sample(\n",
    "                x, t, torch.rand((*x.shape, self.num_classses), device=x.device)\n",
    "            )\n",
    "        return x\n",
    "\n",
    "    def sample_with_image_sequence(self, x, stride=10):\n",
    "        steps = 0\n",
    "        images = []\n",
    "        for t in reversed(range(1, self.n_T)):\n",
    "            t = torch.tensor([t] * x.shape[0], device=x.device)\n",
    "            x = self.p_sample(\n",
    "                x, t, torch.rand((*x.shape, self.num_classses), device=x.device)\n",
    "            )\n",
    "            steps += 1\n",
    "            if steps % stride == 0:\n",
    "                images.append(x)\n",
    "\n",
    "        # if last step is not divisible by stride, we add the last image.\n",
    "        if steps % stride != 0:\n",
    "            images.append(x)\n",
    "\n",
    "        return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T18:28:42.005022Z",
     "iopub.status.busy": "2024-12-04T18:28:42.004769Z",
     "iopub.status.idle": "2024-12-04T18:28:42.029165Z",
     "shell.execute_reply": "2024-12-04T18:28:42.028473Z",
     "shell.execute_reply.started": "2024-12-04T18:28:42.004998Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Swish(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(x)\n",
    "\n",
    "\n",
    "class GaussianFourierEmbedding(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        assert dim % 2 == 0, \"Dimension must be even for equal number of sin and cos\"\n",
    "        self.W = nn.Parameter(torch.randn(dim//2), requires_grad=False)\n",
    "        \n",
    "    def forward(self, t):\n",
    "        t_proj = t[:, None] * self.W[None, :] * 2 * np.pi\n",
    "        return torch.cat([torch.sin(t_proj), torch.cos(t_proj)], dim=-1)\n",
    "\n",
    "\n",
    "class DownSample(nn.Module):\n",
    "    def __init__(self, in_ch):\n",
    "        super().__init__()\n",
    "        self.main = nn.Conv2d(in_ch, in_ch, 3, stride=2, padding=1)\n",
    "        self.initialize()\n",
    "\n",
    "    def initialize(self):\n",
    "        init.xavier_uniform_(self.main.weight)\n",
    "        init.zeros_(self.main.bias)\n",
    "\n",
    "    def forward(self, x, temb):\n",
    "        x = self.main(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class UpSample(nn.Module):\n",
    "    def __init__(self, in_ch):\n",
    "        super().__init__()\n",
    "        self.main = nn.Conv2d(in_ch, in_ch, 3, stride=1, padding=1)\n",
    "        self.initialize()\n",
    "\n",
    "    def initialize(self):\n",
    "        init.xavier_uniform_(self.main.weight)\n",
    "        init.zeros_(self.main.bias)\n",
    "\n",
    "    def forward(self, x, temb):\n",
    "        _, _, H, W = x.shape\n",
    "        x = F.interpolate(\n",
    "            x, scale_factor=2, mode='nearest')\n",
    "        x = self.main(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class AttnBlock(nn.Module):\n",
    "    def __init__(self, in_ch):\n",
    "        super().__init__()\n",
    "        self.group_norm = nn.GroupNorm(32, in_ch)\n",
    "        self.proj_q = nn.Conv2d(in_ch, in_ch, 1, stride=1, padding=0)\n",
    "        self.proj_k = nn.Conv2d(in_ch, in_ch, 1, stride=1, padding=0)\n",
    "        self.proj_v = nn.Conv2d(in_ch, in_ch, 1, stride=1, padding=0)\n",
    "        self.proj = nn.Conv2d(in_ch, in_ch, 1, stride=1, padding=0)\n",
    "        self.initialize()\n",
    "\n",
    "    def initialize(self):\n",
    "        for module in [self.proj_q, self.proj_k, self.proj_v, self.proj]:\n",
    "            init.xavier_uniform_(module.weight)\n",
    "            init.zeros_(module.bias)\n",
    "        init.xavier_uniform_(self.proj.weight, gain=1e-5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        h = self.group_norm(x)\n",
    "        q = self.proj_q(h)\n",
    "        k = self.proj_k(h)\n",
    "        v = self.proj_v(h)\n",
    "\n",
    "        q = q.permute(0, 2, 3, 1).view(B, H * W, C)\n",
    "        k = k.view(B, C, H * W)\n",
    "        w = torch.bmm(q, k) * (int(C) ** (-0.5))\n",
    "        assert list(w.shape) == [B, H * W, H * W]\n",
    "        w = F.softmax(w, dim=-1)\n",
    "\n",
    "        v = v.permute(0, 2, 3, 1).view(B, H * W, C)\n",
    "        h = torch.bmm(w, v)\n",
    "        assert list(h.shape) == [B, H * W, C]\n",
    "        h = h.view(B, H, W, C).permute(0, 3, 1, 2)\n",
    "        h = self.proj(h)\n",
    "\n",
    "        return x + h\n",
    "\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, tdim, dropout, attn=False):\n",
    "        super().__init__()\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.GroupNorm(32, in_ch),\n",
    "            Swish(),\n",
    "            nn.Conv2d(in_ch, out_ch, 3, stride=1, padding=1),\n",
    "        )\n",
    "        self.temb_proj = nn.Sequential(\n",
    "            Swish(),\n",
    "            nn.Linear(tdim, out_ch),\n",
    "        )\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.GroupNorm(32, out_ch),\n",
    "            Swish(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, stride=1, padding=1),\n",
    "        )\n",
    "        if in_ch != out_ch:\n",
    "            self.shortcut = nn.Conv2d(in_ch, out_ch, 1, stride=1, padding=0)\n",
    "        else:\n",
    "            self.shortcut = nn.Identity()\n",
    "        if attn:\n",
    "            self.attn = AttnBlock(out_ch)\n",
    "        else:\n",
    "            self.attn = nn.Identity()\n",
    "        self.initialize()\n",
    "\n",
    "    def initialize(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, (nn.Conv2d, nn.Linear)):\n",
    "                init.xavier_uniform_(module.weight)\n",
    "                init.zeros_(module.bias)\n",
    "        init.xavier_uniform_(self.block2[-1].weight, gain=1e-5)\n",
    "\n",
    "    def forward(self, x, temb):\n",
    "        h = self.block1(x)\n",
    "        h += self.temb_proj(temb)[:, :, None, None]\n",
    "        h = self.block2(h)\n",
    "\n",
    "        h = h + self.shortcut(x)\n",
    "        h = self.attn(h)\n",
    "        return h\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_ch, ch, ch_mult, attn, num_res_blocks, dropout, num_classes):\n",
    "        super().__init__()\n",
    "        assert all([i < len(ch_mult) for i in attn]), 'attn index out of bound'\n",
    "        tdim = ch * 4\n",
    "        self.num_classes = num_classes\n",
    "        self.time_embedding = GaussianFourierEmbedding(tdim)\n",
    "\n",
    "        self.head = nn.Conv2d(in_ch, ch, kernel_size=3, stride=1, padding=1)\n",
    "        self.downblocks = nn.ModuleList()\n",
    "        chs = [ch]  # record output channel when dowmsample for upsample\n",
    "        now_ch = ch\n",
    "        for i, mult in enumerate(ch_mult):\n",
    "            out_ch = ch * mult\n",
    "            for _ in range(num_res_blocks):\n",
    "                self.downblocks.append(ResBlock(\n",
    "                    in_ch=now_ch, out_ch=out_ch, tdim=tdim,\n",
    "                    dropout=dropout, attn=(i in attn)))\n",
    "                now_ch = out_ch\n",
    "                chs.append(now_ch)\n",
    "            if i != len(ch_mult) - 1:\n",
    "                self.downblocks.append(DownSample(now_ch))\n",
    "                chs.append(now_ch)\n",
    "\n",
    "        self.middleblocks = nn.ModuleList([\n",
    "            ResBlock(now_ch, now_ch, tdim, dropout, attn=True),\n",
    "            ResBlock(now_ch, now_ch, tdim, dropout, attn=False),\n",
    "        ])\n",
    "\n",
    "        self.upblocks = nn.ModuleList()\n",
    "        for i, mult in reversed(list(enumerate(ch_mult))):\n",
    "            out_ch = ch * mult\n",
    "            for _ in range(num_res_blocks + 1):\n",
    "                self.upblocks.append(ResBlock(\n",
    "                    in_ch=chs.pop() + now_ch, out_ch=out_ch, tdim=tdim,\n",
    "                    dropout=dropout, attn=(i in attn)))\n",
    "                now_ch = out_ch\n",
    "            if i != 0:\n",
    "                self.upblocks.append(UpSample(now_ch))\n",
    "        assert len(chs) == 0\n",
    "\n",
    "        self.tail = nn.Sequential(\n",
    "            nn.GroupNorm(32, now_ch),\n",
    "            Swish(),\n",
    "            nn.Conv2d(now_ch, in_ch*num_classes, 3, stride=1, padding=1)\n",
    "        )\n",
    "        self.initialize()\n",
    "\n",
    "    def initialize(self):\n",
    "        init.xavier_uniform_(self.head.weight)\n",
    "        init.zeros_(self.head.bias)\n",
    "        init.xavier_uniform_(self.tail[-1].weight, gain=1e-5)\n",
    "        init.zeros_(self.tail[-1].bias)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        # Timestep embedding\n",
    "        temb = self.time_embedding(t)\n",
    "        # Downsampling\n",
    "        # print(self.head)\n",
    "        h = self.head(x.float())\n",
    "        hs = [h]\n",
    "        for layer in self.downblocks:\n",
    "            h = layer(h, temb)\n",
    "            hs.append(h)\n",
    "        # Middle\n",
    "        for layer in self.middleblocks:\n",
    "            h = layer(h, temb)\n",
    "        # Upsampling\n",
    "        for layer in self.upblocks:\n",
    "            if isinstance(layer, ResBlock):\n",
    "                h = torch.cat([h, hs.pop()], dim=1)\n",
    "            h = layer(h, temb)\n",
    "        h = self.tail(h)\n",
    "\n",
    "        assert len(hs) == 0\n",
    "        B, INxN, H, W = h.shape\n",
    "        h = h.view(B, INxN // self.num_classes, H, W, self.num_classes)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T09:01:23.072477Z",
     "iopub.status.busy": "2024-12-04T09:01:23.072112Z",
     "iopub.status.idle": "2024-12-04T09:27:36.062633Z",
     "shell.execute_reply": "2024-12-04T09:27:36.061773Z",
     "shell.execute_reply.started": "2024-12-04T09:01:23.072444Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    import os\n",
    "    if not os.path.exists('unconditional'):\n",
    "        os.makedirs('unconditional')\n",
    "\n",
    "    N = 2  # number of classes for discretized state per pixel\n",
    "    model = UNet(in_ch=1, ch=64, ch_mult=[1,2], attn=[], num_res_blocks=2, dropout=0.15, num_classes=N)\n",
    "    d3pm = D3PM(model, 1000, num_classes=N, hybrid_loss_coeff=0.0).cuda()\n",
    "    print(f\"Total Param Count: {sum([p.numel() for p in d3pm.x0_model.parameters()])}\")\n",
    "    dataset = MNIST(\n",
    "        \"./data\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Pad(2),\n",
    "            ]\n",
    "        ),\n",
    "    )\n",
    "    dataloader = DataLoader(dataset, batch_size=256, shuffle=True, num_workers=32)\n",
    "\n",
    "    optim = torch.optim.AdamW(d3pm.x0_model.parameters(), lr=1e-3)\n",
    "    d3pm.train()\n",
    "\n",
    "    n_epoch = 10\n",
    "    device = \"cuda\"\n",
    "\n",
    "    global_step = 0\n",
    "    for i in range(n_epoch):\n",
    "\n",
    "        pbar = tqdm(dataloader)\n",
    "        loss_ema = None\n",
    "        for x, cond in pbar:\n",
    "            optim.zero_grad()\n",
    "            x = x.to(device)\n",
    "            cond = torch.tensor(1).long().to(device)\n",
    "\n",
    "            # discritize x to N bins\n",
    "            x = (x * (N - 1)).round().long().clamp(0, N - 1)\n",
    "            loss, info = d3pm(x)\n",
    "\n",
    "            loss.backward()\n",
    "            norm = torch.nn.utils.clip_grad_norm_(d3pm.x0_model.parameters(), 0.1)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                param_norm = sum([torch.norm(p) for p in d3pm.x0_model.parameters()])\n",
    "\n",
    "            if loss_ema is None:\n",
    "                loss_ema = loss.item()\n",
    "            else:\n",
    "                loss_ema = 0.99 * loss_ema + 0.01 * loss.item()\n",
    "            pbar.set_description(\n",
    "                f\"loss: {loss_ema:.4f}, norm: {norm:.4f}, param_norm: {param_norm:.4f}, vb_loss: {info['vb_loss']:.4f}, ce_loss: {info['ce_loss']:.4f}\"\n",
    "            )\n",
    "            optim.step()\n",
    "            global_step += 1\n",
    "\n",
    "        d3pm.eval()\n",
    "        with torch.no_grad():\n",
    "            # cond = torch.ones((4,)).long().cuda() % 10\n",
    "            init_noise = torch.randint(0, N, (4, 1, 32, 32)).cuda()\n",
    "\n",
    "            images = d3pm.sample_with_image_sequence(\n",
    "                init_noise, stride=40\n",
    "            )\n",
    "            # image sequences to gif\n",
    "            gif = []\n",
    "            for image in images:\n",
    "                x_as_image = make_grid(image.float() / (N - 1), nrow=2)\n",
    "                img = x_as_image.permute(1, 2, 0).cpu().numpy()\n",
    "                img = (img * 255).astype(np.uint8)\n",
    "                gif.append(Image.fromarray(img))\n",
    "\n",
    "            gif[0].save(\n",
    "                f\"unconditional/sample_{i}.gif\",\n",
    "                save_all=True,\n",
    "                append_images=gif[1:],\n",
    "                duration=100,\n",
    "                loop=0,\n",
    "            )\n",
    "\n",
    "            last_img = gif[-1]\n",
    "            last_img.save(f\"unconditional/sample_{i}_last.png\")\n",
    "\n",
    "        d3pm.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T09:00:37.935546Z",
     "iopub.status.busy": "2024-12-04T09:00:37.935179Z",
     "iopub.status.idle": "2024-12-04T09:00:50.305601Z",
     "shell.execute_reply": "2024-12-04T09:00:50.304844Z",
     "shell.execute_reply.started": "2024-12-04T09:00:37.935516Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "d3pm.eval()\n",
    "with torch.no_grad():\n",
    "    # cond = torch.ones((4,)).long().cuda() % 10\n",
    "    init_noise = torch.randint(0, 2, (32, 1, 32, 32)).cuda()\n",
    "\n",
    "    images = d3pm.sample_with_image_sequence(\n",
    "        init_noise, stride=40\n",
    "    )\n",
    "    # image sequences to gif\n",
    "    gif = []\n",
    "    for image in images:\n",
    "        x_as_image = make_grid(image.float() / (N - 1), nrow=8)\n",
    "        img = x_as_image.permute(1, 2, 0).cpu().numpy()\n",
    "        img = (img * 255).astype(np.uint8)\n",
    "        gif.append(Image.fromarray(img))\n",
    "\n",
    "\n",
    "    last_img = gif[-1]\n",
    "    last_img.save(f\"unconditional/sample_{i}_last.png\")\n",
    "    # fig, ax = plt.subplots(4, 8, figsize=(32, 16))\n",
    "    # for i in range(32):\n",
    "    #     ax[i//8, i%8].imshow(last_img[i], cmap='gray')\n",
    "    #     ax[i//8, i%8].axis('off')\n",
    "    plt.imshow(last_img)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkerboard Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T18:30:07.079379Z",
     "iopub.status.busy": "2024-12-04T18:30:07.079030Z",
     "iopub.status.idle": "2024-12-04T18:30:07.085938Z",
     "shell.execute_reply": "2024-12-04T18:30:07.085023Z",
     "shell.execute_reply.started": "2024-12-04T18:30:07.079344Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def inf_train_gen(n_grid_points: int = 128, batch_size: int = 200, device: str = \"cpu\", num_squares=4, seed: int = 0):\n",
    "    assert n_grid_points % num_squares == 0, \"number of grid points has to be divisible by num_squares\"\n",
    "    assert num_squares % 2 == 0, \"num_squares has to be even\"\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "    n_grid_points = n_grid_points // num_squares\n",
    "    \n",
    "    x1 = torch.randint(low=0, high=n_grid_points * num_squares, size=(batch_size,), device=device)  # any random point on the checkerboard - (y)\n",
    "    samples_x2 = torch.randint(low=0, high=n_grid_points, size=(batch_size,), device=device)  # sample an x value within a square\n",
    "    \n",
    "    x2 = (\n",
    "        samples_x2\n",
    "        + (num_squares-2) * n_grid_points  # moving to the final two columns of squares: (num_squares-1, num_squares)\n",
    "        - torch.randint(low=0, high=num_squares//2, size=(batch_size,), device=device) * 2 * n_grid_points  # moving to any of the other pairs of columns\n",
    "        + (torch.floor(x1 / n_grid_points) % 2) * n_grid_points  # if in an even numbered row of squares, move to the square to the right.\n",
    "    )  # x2 is an (x) point that paired with x1 will always correspond to a point within a square that is \"white\" (assuming the diagonal is white).\n",
    "    \n",
    "    x_end = 1.0 * torch.cat([x1[:, None], x2[:, None]], dim=1)  # why are we multiplying by 1.0?\n",
    "    return x_end.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T18:30:17.696659Z",
     "iopub.status.busy": "2024-12-04T18:30:17.696332Z",
     "iopub.status.idle": "2024-12-04T18:30:17.702164Z",
     "shell.execute_reply": "2024-12-04T18:30:17.701373Z",
     "shell.execute_reply.started": "2024-12-04T18:30:17.696631Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(torch.cuda.memory_summary(device=None, abbreviated=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T20:23:47.650920Z",
     "iopub.status.busy": "2024-12-04T20:23:47.650572Z",
     "iopub.status.idle": "2024-12-04T20:23:47.661880Z",
     "shell.execute_reply": "2024-12-04T20:23:47.661156Z",
     "shell.execute_reply.started": "2024-12-04T20:23:47.650889Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_checkerboard1(n_grid_points: int = 128, batch_size: int = 200, device: str = \"cpu\", num_squares=4, seed=0):\n",
    "    \"\"\"Creates a black image and adds noise to where white tiles would be\"\"\"\n",
    "    generated = inf_train_gen(n_grid_points, batch_size, device, num_squares, seed)\n",
    "    image = torch.zeros(n_grid_points, n_grid_points)\n",
    "    image[generated[:, 0], generated[:, 1]] = 1\n",
    "    return image\n",
    "\n",
    "def create_checkerboard2(n_grid_points: int = 128, batch_size: int = 200, device: str = \"cpu\", num_squares=4, seed=0):\n",
    "    \"\"\"Creates a checkerboard and adds noise to white tiles\"\"\"\n",
    "    generated = inf_train_gen(n_grid_points, batch_size, device, num_squares, seed)\n",
    "    image = torch.zeros(n_grid_points, n_grid_points)\n",
    "    # white out the squares that would be white in a checkerboard\n",
    "    for i in range(num_squares):\n",
    "        for j in range(num_squares):\n",
    "            if (i + j) % 2 == 0:\n",
    "                image[i * n_grid_points // num_squares:(i + 1) * n_grid_points // num_squares,\n",
    "                      j * n_grid_points // num_squares:(j + 1) * n_grid_points // num_squares] = 1\n",
    "    \n",
    "    image[generated[:, 0], generated[:, 1]] = 0\n",
    "    return image\n",
    "\n",
    "def create_checkerboard3(n_grid_points: int = 128, batch_size: int = 200, device: str = \"cpu\", num_squares=4, seed=0):\n",
    "    \"\"\"Creates a checkerboard with a random switch between where white and black can be\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    p = torch.rand(2) > 0.5\n",
    "    checkerboard2 = create_checkerboard2(n_grid_points, batch_size, device, num_squares, seed)\n",
    "    if p[0]:\n",
    "        checkerboard2 = torch.roll(checkerboard2, shifts=n_grid_points // num_squares, dims=1)\n",
    "    checkerboard2 = p[1]*checkerboard2 + (~p[1]) * (1 - checkerboard2)\n",
    "    return checkerboard2\n",
    "\n",
    "def create_checkerboard4(n_grid_points: int = 128, batch_size: int = 200, device: str = \"cpu\", num_squares=8, seed=0):\n",
    "    \"\"\"Creates a checkerboard with a random switch between where white and black can be\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    num_squares = 2 ** np.random.randint(1, int(np.log2(num_squares))+1)\n",
    "    return create_checkerboard3(n_grid_points, batch_size, device, num_squares, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T18:31:38.957347Z",
     "iopub.status.busy": "2024-12-04T18:31:38.956653Z",
     "iopub.status.idle": "2024-12-04T18:31:39.302565Z",
     "shell.execute_reply": "2024-12-04T18:31:39.301847Z",
     "shell.execute_reply.started": "2024-12-04T18:31:38.957315Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "SIZE = 256\n",
    "SEED = 89\n",
    "\n",
    "image1 = create_checkerboard1(n_grid_points=SIZE, batch_size=10000, seed=SEED)\n",
    "image2 = create_checkerboard2(n_grid_points=SIZE, batch_size=10000, seed=SEED)\n",
    "image3 = create_checkerboard3(n_grid_points=SIZE, batch_size=10000, seed=SEED)\n",
    "image4 = create_checkerboard4(n_grid_points=SIZE, batch_size=10000, seed=SEED)\n",
    "\n",
    "# add lines for every 32 pixels\n",
    "# image[::SIZE//4, :] = 1\n",
    "# image[:, ::SIZE//4] = 1\n",
    "\n",
    "fig, ax = plt.subplots(1, 4, figsize=(10, 5))\n",
    "ax[0].imshow(image1, cmap='gray')\n",
    "ax[0].axis('off')\n",
    "ax[1].imshow(image2, cmap='gray')\n",
    "ax[1].axis('off')\n",
    "ax[2].imshow(image3, cmap='gray')\n",
    "ax[2].axis('off')\n",
    "ax[3].imshow(image4, cmap='gray')\n",
    "ax[3].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T19:21:22.709056Z",
     "iopub.status.busy": "2024-12-04T19:21:22.708168Z",
     "iopub.status.idle": "2024-12-04T19:21:22.721461Z",
     "shell.execute_reply": "2024-12-04T19:21:22.720627Z",
     "shell.execute_reply.started": "2024-12-04T19:21:22.709011Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# create a dataset of images with a checkerboard pattern\n",
    "# each image is 128 x 128 pixels\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class CheckerboardDataset(Dataset):\n",
    "    def __init__(self, dataset_size, n_grid_points: int = 128, batch_size: int = 200, device: str = \"cpu\", num_squares=4, method=create_checkerboard1):\n",
    "        self.dataset_size = dataset_size\n",
    "        self.n_grid_points = n_grid_points\n",
    "        self.batch_size = batch_size\n",
    "        self.device = device\n",
    "        self.num_squares = num_squares\n",
    "        self.seeds = torch.randint(0, 100000, size=(dataset_size,))\n",
    "        self.method = method\n",
    "        self.items = self.generate_items()\n",
    "\n",
    "    def generate_items(self):\n",
    "        dataset = [self.method(n_grid_points=self.n_grid_points, batch_size=self.batch_size, device=self.device, num_squares=self.num_squares, seed=self.seeds[idx]) for idx in range(len(self))]\n",
    "        dataset = torch.stack(dataset, dim=0).unsqueeze(1)\n",
    "        return dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset_size\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.items[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T18:55:22.707253Z",
     "iopub.status.busy": "2024-12-04T18:55:22.706395Z",
     "iopub.status.idle": "2024-12-04T19:02:29.452458Z",
     "shell.execute_reply": "2024-12-04T19:02:29.451769Z",
     "shell.execute_reply.started": "2024-12-04T18:55:22.707218Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "for method in (create_checkerboard4, create_checkerboard3, create_checkerboard2, create_checkerboard1):\n",
    "    if not os.path.exists(method.__name__):\n",
    "        os.makedirs(method.__name__)\n",
    "    print(f'Generating for {method.__name__}')\n",
    "    N = 2  # number of classes for discretized state per pixel\n",
    "    model = UNet(in_ch=1, ch=64, ch_mult=[1,2], attn=[], num_res_blocks=2, dropout=0.15, num_classes=N)\n",
    "    d3pm = D3PM(model, 1000, num_classes=N, hybrid_loss_coeff=0.0).cuda()\n",
    "    print(f\"Total Param Count: {sum([p.numel() for p in d3pm.x0_model.parameters()])}\")\n",
    "    dataset = CheckerboardDataset(1000, n_grid_points=32, method=method)\n",
    "    dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "    optim = torch.optim.AdamW(d3pm.x0_model.parameters(), lr=1e-3)\n",
    "    d3pm.train()\n",
    "\n",
    "    n_epoch = 10\n",
    "    device = \"cuda\"\n",
    "\n",
    "    global_step = 0\n",
    "    for i in range(n_epoch):\n",
    "\n",
    "        pbar = tqdm(dataloader)\n",
    "        loss_ema = None\n",
    "        for x in pbar:\n",
    "            optim.zero_grad()\n",
    "            x = x.to(device)\n",
    "            cond = torch.tensor(1).long().to(device)\n",
    "\n",
    "            # discritize x to N bins\n",
    "            x = (x * (N - 1)).round().long().clamp(0, N - 1)\n",
    "            loss, info = d3pm(x)\n",
    "\n",
    "            loss.backward()\n",
    "            norm = torch.nn.utils.clip_grad_norm_(d3pm.x0_model.parameters(), 0.1)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                param_norm = sum([torch.norm(p) for p in d3pm.x0_model.parameters()])\n",
    "\n",
    "            if loss_ema is None:\n",
    "                loss_ema = loss.item()\n",
    "            else:\n",
    "                loss_ema = 0.99 * loss_ema + 0.01 * loss.item()\n",
    "            pbar.set_description(\n",
    "                f\"loss: {loss_ema:.4f}, norm: {norm:.4f}, param_norm: {param_norm:.4f}, vb_loss: {info['vb_loss']:.4f}, ce_loss: {info['ce_loss']:.4f}\"\n",
    "            )\n",
    "            optim.step()\n",
    "            global_step += 1\n",
    "\n",
    "        d3pm.eval()\n",
    "        with torch.no_grad():\n",
    "            # cond = torch.ones((4,)).long().cuda() % 10\n",
    "            init_noise = torch.randint(0, N, (4, 1, 32, 32)).cuda()\n",
    "\n",
    "            images = d3pm.sample_with_image_sequence(\n",
    "                init_noise, stride=40\n",
    "            )\n",
    "            # image sequences to gif\n",
    "            gif = []\n",
    "            for image in images:\n",
    "                x_as_image = make_grid(image.float() / (N - 1), nrow=2)\n",
    "                img = x_as_image.permute(1, 2, 0).cpu().numpy()\n",
    "                img = (img * 255).astype(np.uint8)\n",
    "                gif.append(Image.fromarray(img))\n",
    "\n",
    "            gif[0].save(\n",
    "                f\"{method.__name__}/sample_{i}.gif\",\n",
    "                save_all=True,\n",
    "                append_images=gif[1:],\n",
    "                duration=100,\n",
    "                loop=0,\n",
    "            )\n",
    "\n",
    "            last_img = gif[-1]\n",
    "            last_img.save(f\"{method.__name__}/sample_{i}_last.png\")\n",
    "\n",
    "        d3pm.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using regular (not discrete) DDPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T19:50:05.677496Z",
     "iopub.status.busy": "2024-12-04T19:50:05.677141Z",
     "iopub.status.idle": "2024-12-04T19:50:05.714509Z",
     "shell.execute_reply": "2024-12-04T19:50:05.713691Z",
     "shell.execute_reply.started": "2024-12-04T19:50:05.677463Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def gather_reshape(v, t, x_shape):\n",
    "    \"\"\"\n",
    "    :param v: tensor of parameters (such as beta)\n",
    "    :param t: tensor of indices, for each element in batch has a corresponding index\n",
    "    :param x_shape: shape of the output tensor (to easily find x_t)\n",
    "    \"\"\"\n",
    "    out = torch.gather(v, index=t, dim=0).float().to(device)\n",
    "    return out.view([t.shape[0]] + [1] * (len(x_shape) - 1))\n",
    "\n",
    "\n",
    "class Swish(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(x)\n",
    "\n",
    "\n",
    "class TimeEmbedding(nn.Module):\n",
    "    def __init__(self, T, d_model, dim):\n",
    "        super().__init__()\n",
    "        emb = torch.arange(0, d_model, step=2) / d_model * np.log(10000)\n",
    "        emb = torch.exp(-emb)\n",
    "        pos = torch.arange(T).float()\n",
    "        emb = pos[:, None] * emb[None, :]\n",
    "        emb = torch.stack([torch.sin(emb), torch.cos(emb)], dim=-1)\n",
    "        emb = emb.view(T, d_model)\n",
    "\n",
    "        self.timembedding = nn.Sequential(\n",
    "            nn.Embedding.from_pretrained(emb),\n",
    "            nn.Linear(d_model, dim),\n",
    "            Swish(),\n",
    "            nn.Linear(dim, dim),\n",
    "        )\n",
    "        self.initialize()\n",
    "\n",
    "    def initialize(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                init.xavier_uniform_(module.weight)\n",
    "                init.zeros_(module.bias)\n",
    "\n",
    "    def forward(self, t):\n",
    "        emb = self.timembedding(t)\n",
    "        return emb\n",
    "\n",
    "\n",
    "class DownSample(nn.Module):\n",
    "    def __init__(self, in_ch):\n",
    "        super().__init__()\n",
    "        self.main = nn.Conv2d(in_ch, in_ch, 3, stride=2, padding=1)\n",
    "        self.initialize()\n",
    "\n",
    "    def initialize(self):\n",
    "        init.xavier_uniform_(self.main.weight)\n",
    "        init.zeros_(self.main.bias)\n",
    "\n",
    "    def forward(self, x, temb):\n",
    "        x = self.main(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class UpSample(nn.Module):\n",
    "    def __init__(self, in_ch):\n",
    "        super().__init__()\n",
    "        self.main = nn.Conv2d(in_ch, in_ch, 3, stride=1, padding=1)\n",
    "        self.initialize()\n",
    "\n",
    "    def initialize(self):\n",
    "        init.xavier_uniform_(self.main.weight)\n",
    "        init.zeros_(self.main.bias)\n",
    "\n",
    "    def forward(self, x, temb):\n",
    "        _, _, H, W = x.shape\n",
    "        x = F.interpolate(\n",
    "            x, scale_factor=2, mode='nearest')\n",
    "        x = self.main(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class AttnBlock(nn.Module):\n",
    "    def __init__(self, in_ch):\n",
    "        super().__init__()\n",
    "        self.group_norm = nn.GroupNorm(32, in_ch)\n",
    "        self.proj_q = nn.Conv2d(in_ch, in_ch, 1, stride=1, padding=0)\n",
    "        self.proj_k = nn.Conv2d(in_ch, in_ch, 1, stride=1, padding=0)\n",
    "        self.proj_v = nn.Conv2d(in_ch, in_ch, 1, stride=1, padding=0)\n",
    "        self.proj = nn.Conv2d(in_ch, in_ch, 1, stride=1, padding=0)\n",
    "        self.initialize()\n",
    "\n",
    "    def initialize(self):\n",
    "        for module in [self.proj_q, self.proj_k, self.proj_v, self.proj]:\n",
    "            init.xavier_uniform_(module.weight)\n",
    "            init.zeros_(module.bias)\n",
    "        init.xavier_uniform_(self.proj.weight, gain=1e-5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        h = self.group_norm(x)\n",
    "        q = self.proj_q(h)\n",
    "        k = self.proj_k(h)\n",
    "        v = self.proj_v(h)\n",
    "\n",
    "        q = q.permute(0, 2, 3, 1).view(B, H * W, C)\n",
    "        k = k.view(B, C, H * W)\n",
    "        w = torch.bmm(q, k) * (int(C) ** (-0.5))\n",
    "        assert list(w.shape) == [B, H * W, H * W]\n",
    "        w = F.softmax(w, dim=-1)\n",
    "\n",
    "        v = v.permute(0, 2, 3, 1).view(B, H * W, C)\n",
    "        h = torch.bmm(w, v)\n",
    "        assert list(h.shape) == [B, H * W, C]\n",
    "        h = h.view(B, H, W, C).permute(0, 3, 1, 2)\n",
    "        h = self.proj(h)\n",
    "\n",
    "        return x + h\n",
    "\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, tdim, dropout, attn=False):\n",
    "        super().__init__()\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.GroupNorm(32, in_ch),\n",
    "            Swish(),\n",
    "            nn.Conv2d(in_ch, out_ch, 3, stride=1, padding=1),\n",
    "        )\n",
    "        self.temb_proj = nn.Sequential(\n",
    "            Swish(),\n",
    "            nn.Linear(tdim, out_ch),\n",
    "        )\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.GroupNorm(32, out_ch),\n",
    "            Swish(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, stride=1, padding=1),\n",
    "        )\n",
    "        if in_ch != out_ch:\n",
    "            self.shortcut = nn.Conv2d(in_ch, out_ch, 1, stride=1, padding=0)\n",
    "        else:\n",
    "            self.shortcut = nn.Identity()\n",
    "        if attn:\n",
    "            self.attn = AttnBlock(out_ch)\n",
    "        else:\n",
    "            self.attn = nn.Identity()\n",
    "        self.initialize()\n",
    "\n",
    "    def initialize(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, (nn.Conv2d, nn.Linear)):\n",
    "                init.xavier_uniform_(module.weight)\n",
    "                init.zeros_(module.bias)\n",
    "        init.xavier_uniform_(self.block2[-1].weight, gain=1e-5)\n",
    "\n",
    "    def forward(self, x, temb):\n",
    "        h = self.block1(x)\n",
    "        h += self.temb_proj(temb)[:, :, None, None]\n",
    "        h = self.block2(h)\n",
    "\n",
    "        h = h + self.shortcut(x)\n",
    "        h = self.attn(h)\n",
    "        return h\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, T, ch, ch_mult, attn, num_res_blocks, dropout):\n",
    "        super().__init__()\n",
    "        assert all([i < len(ch_mult) for i in attn]), 'attn index out of bound'\n",
    "        tdim = ch * 4\n",
    "        self.time_embedding = TimeEmbedding(T, ch, tdim)\n",
    "\n",
    "        self.head = nn.Conv2d(1, ch, kernel_size=3, stride=1, padding=1)\n",
    "        self.downblocks = nn.ModuleList()\n",
    "        chs = [ch]  # record output channel when dowmsample for upsample\n",
    "        now_ch = ch\n",
    "        for i, mult in enumerate(ch_mult):\n",
    "            out_ch = ch * mult\n",
    "            for _ in range(num_res_blocks):\n",
    "                self.downblocks.append(ResBlock(\n",
    "                    in_ch=now_ch, out_ch=out_ch, tdim=tdim,\n",
    "                    dropout=dropout, attn=(i in attn)))\n",
    "                now_ch = out_ch\n",
    "                chs.append(now_ch)\n",
    "            if i != len(ch_mult) - 1:\n",
    "                self.downblocks.append(DownSample(now_ch))\n",
    "                chs.append(now_ch)\n",
    "\n",
    "        self.middleblocks = nn.ModuleList([\n",
    "            ResBlock(now_ch, now_ch, tdim, dropout, attn=True),\n",
    "            ResBlock(now_ch, now_ch, tdim, dropout, attn=False),\n",
    "        ])\n",
    "\n",
    "        self.upblocks = nn.ModuleList()\n",
    "        for i, mult in reversed(list(enumerate(ch_mult))):\n",
    "            out_ch = ch * mult\n",
    "            for _ in range(num_res_blocks + 1):\n",
    "                self.upblocks.append(ResBlock(\n",
    "                    in_ch=chs.pop() + now_ch, out_ch=out_ch, tdim=tdim,\n",
    "                    dropout=dropout, attn=(i in attn)))\n",
    "                now_ch = out_ch\n",
    "            if i != 0:\n",
    "                self.upblocks.append(UpSample(now_ch))\n",
    "        assert len(chs) == 0\n",
    "\n",
    "        self.tail = nn.Sequential(\n",
    "            nn.GroupNorm(32, now_ch),\n",
    "            Swish(),\n",
    "            nn.Conv2d(now_ch, 1, 3, stride=1, padding=1)\n",
    "        )\n",
    "        self.initialize()\n",
    "\n",
    "    def initialize(self):\n",
    "        init.xavier_uniform_(self.head.weight)\n",
    "        init.zeros_(self.head.bias)\n",
    "        init.xavier_uniform_(self.tail[-1].weight, gain=1e-5)\n",
    "        init.zeros_(self.tail[-1].bias)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        # Timestep embedding\n",
    "        temb = self.time_embedding(t)\n",
    "        # Downsampling\n",
    "        h = self.head(x)\n",
    "        hs = [h]\n",
    "        for layer in self.downblocks:\n",
    "            h = layer(h, temb)\n",
    "            hs.append(h)\n",
    "        # Middle\n",
    "        for layer in self.middleblocks:\n",
    "            h = layer(h, temb)\n",
    "        # Upsampling\n",
    "        for layer in self.upblocks:\n",
    "            if isinstance(layer, ResBlock):\n",
    "                h = torch.cat([h, hs.pop()], dim=1)\n",
    "            h = layer(h, temb)\n",
    "        h = self.tail(h)\n",
    "\n",
    "        assert len(hs) == 0\n",
    "        return h\n",
    "\n",
    "\n",
    "class DiffusionLoss(nn.Module):\n",
    "    def __init__(self, T, model, beta_1, beta_T):\n",
    "        super().__init__()\n",
    "        self.T = T\n",
    "        self.model = model\n",
    "        self.register_buffer('beta', torch.linspace(beta_1, beta_T, T))\n",
    "        a = 1 - self.beta\n",
    "        alpha = torch.cumprod(a, 0)\n",
    "        self.register_buffer('sqrt_alpha', alpha.sqrt())\n",
    "        self.register_buffer('sqrt_1m_alpha', (1 - alpha).sqrt())\n",
    "\n",
    "    def forward(self, train_x):\n",
    "        B, C, H, W = train_x.shape\n",
    "        t = torch.randint(self.T, (B, )).to(device)  # time index is uniform (int)\n",
    "        noise = torch.randn_like(train_x).to(device)  # epsilon\n",
    "        x_t = gather_reshape(self.sqrt_alpha, t, train_x.shape) * train_x + gather_reshape(self.sqrt_1m_alpha, t, train_x.shape) * noise  # according to equation\n",
    "        loss = F.mse_loss(self.model(x_t, t), noise)\n",
    "        return loss\n",
    "\n",
    "\n",
    "class DiffusionSampler(nn.Module):\n",
    "    def __init__(self, T, model, beta_1, beta_T):\n",
    "        super().__init__()\n",
    "        self.T = T\n",
    "        self.model = model\n",
    "        self.register_buffer('beta', torch.linspace(beta_1, beta_T, T))\n",
    "        a = 1 - self.beta\n",
    "        alpha = torch.cumprod(a, 0)\n",
    "        alpha_padded = F.pad(alpha, [1, 0], value=1)[:T]\n",
    "        self.register_buffer('coeff_prev', 1 / a.sqrt())\n",
    "        self.register_buffer('coeff_noise', self.coeff_prev * (1 - a) / (1 - alpha).sqrt())\n",
    "        self.register_buffer('posterior_var', self.beta * (1. - alpha_padded) / (1. - alpha))\n",
    "        self.register_buffer('variance', torch.cat([self.posterior_var[1:2], self.beta[1:]]))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        for time in reversed(range(self.T)):\n",
    "            if time == 0:\n",
    "                noise = 0\n",
    "            else:\n",
    "                noise = torch.randn_like(x)\n",
    "            t = x.new_ones(x.shape[0], dtype=int) * time\n",
    "            mean = gather_reshape(self.coeff_prev, t, x.shape) * x - gather_reshape(self.coeff_noise, t, x.shape) * self.model(x, t)\n",
    "            var = gather_reshape(self.variance, t, x.shape)\n",
    "            x = mean + torch.sqrt(var) * noise\n",
    "        return x\n",
    "    \n",
    "    def generate_visualize(self):\n",
    "        x = torch.randn(4, 1, 64, 64).to(device)\n",
    "        xs = [x.cpu().detach().numpy()]\n",
    "        for time in reversed(range(self.T)):\n",
    "            t = x.new_ones(x.shape[0], dtype=int) * time\n",
    "            mean = gather_reshape(self.coeff_prev, t, x.shape) * x - gather_reshape(self.coeff_noise, t, x.shape) * self.model(x, t)\n",
    "            var = gather_reshape(self.variance, t, x.shape)\n",
    "            if time == 0:\n",
    "                x = mean\n",
    "            else:\n",
    "                x = mean + torch.sqrt(var) * torch.randn_like(x)\n",
    "            if time % (self.T // 10) == 0:\n",
    "                xs.append(x.cpu().detach().numpy())\n",
    "        return xs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T19:19:01.840053Z",
     "iopub.status.busy": "2024-12-04T19:19:01.839429Z",
     "iopub.status.idle": "2024-12-04T19:19:01.844910Z",
     "shell.execute_reply": "2024-12-04T19:19:01.844005Z",
     "shell.execute_reply.started": "2024-12-04T19:19:01.840026Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "modelConfig = {\n",
    "        \"state\": \"train\",\n",
    "        \"epoch\": 50,\n",
    "        \"batch_size\": 64,\n",
    "        \"T\": 1000,\n",
    "        \"channel\": 32,\n",
    "        \"channel_mult\": [1, 2],\n",
    "        \"attn\": [],\n",
    "        \"num_res_blocks\": 2,\n",
    "        \"dropout\": 0.15,\n",
    "        \"lr\": 5e-4,\n",
    "        \"multiplier\": 2.,\n",
    "        \"beta_1\": 1e-4,\n",
    "        \"beta_T\": 0.02,\n",
    "        \"img_size\": 32,\n",
    "        \"grad_clip\": 1.,\n",
    "        \"device\": \"cuda:0\",\n",
    "        \"training_load_weight\": None,\n",
    "        \"save_weight_dir\": \"./Checkpoints5/\",\n",
    "        \"test_load_weight\": \"ckpt_49_.pt\",\n",
    "        \"sampled_dir\": \"\",\n",
    "        \"sampledNoisyImgName\": \"NoisyNoGuidenceImgs.png\",\n",
    "        \"sampledImgName\": \"SampledDDPM.png\",\n",
    "        \"nrow\": 8,\n",
    "        \"show_process\": True\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T19:50:08.465303Z",
     "iopub.status.busy": "2024-12-04T19:50:08.464920Z",
     "iopub.status.idle": "2024-12-04T20:19:38.628172Z",
     "shell.execute_reply": "2024-12-04T20:19:38.627317Z",
     "shell.execute_reply.started": "2024-12-04T19:50:08.465260Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Dict\n",
    "\n",
    "n_epochs = [5, 5, 10, 10]\n",
    "index = -1\n",
    "\n",
    "for method in [create_checkerboard1, create_checkerboard2, create_checkerboard3, create_checkerboard4]:\n",
    "    index += 1\n",
    "    name = f'{method.__name__}_continuous'\n",
    "    if not os.path.exists(name):\n",
    "        os.makedirs(name)\n",
    "    print(\"Starting with\", method.__name__)\n",
    "    device = torch.device(modelConfig[\"device\"])\n",
    "    # dataset\n",
    "    # Define the transform\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    \n",
    "    train_dataset = CheckerboardDataset(4096, n_grid_points=64, method=method)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    \n",
    "    # model setup\n",
    "    net_model = UNet(T=1000, ch=64, ch_mult=[1,2], attn=[], num_res_blocks=2, dropout=0.15)\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(\n",
    "        net_model.parameters(), lr=modelConfig[\"lr\"], weight_decay=1e-4)\n",
    "    trainer = DiffusionLoss(\n",
    "        modelConfig[\"T\"], net_model, modelConfig[\"beta_1\"], modelConfig[\"beta_T\"]).to(device)\n",
    "    \n",
    "    if not os.path.exists(modelConfig[\"save_weight_dir\"]):\n",
    "        os.makedirs(modelConfig[\"save_weight_dir\"])\n",
    "\n",
    "    for images in train_loader:\n",
    "        fig, ax = plt.subplots(nrows=4, ncols=8, figsize=(8, 4))\n",
    "        for i in range(images.shape[0]):\n",
    "            ax[i // 8, i % 8].imshow(images[i, 0], cmap='gray')\n",
    "            ax[i // 8, i % 8].axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        break\n",
    "    # start training\n",
    "    for e in range(n_epochs[index]):\n",
    "        with tqdm(train_loader, dynamic_ncols=True) as tqdmDataLoader:\n",
    "            for images in tqdmDataLoader:\n",
    "                # train\n",
    "                optimizer.zero_grad()\n",
    "                x_0 = images.to(device)\n",
    "                loss = trainer(x_0)\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(\n",
    "                    net_model.parameters(), modelConfig[\"grad_clip\"])\n",
    "                optimizer.step()\n",
    "                tqdmDataLoader.set_postfix(ordered_dict={\n",
    "                    \"epoch\": e,\n",
    "                    \"loss: \": loss.item(),\n",
    "                    \"img shape: \": x_0.shape,\n",
    "                    \"LR\": optimizer.state_dict()['param_groups'][0][\"lr\"]\n",
    "                })\n",
    "        with torch.no_grad():\n",
    "            sampler = DiffusionSampler(\n",
    "                 modelConfig[\"T\"], net_model, modelConfig[\"beta_1\"], modelConfig[\"beta_T\"]).to(device)\n",
    "            # Sampled from standard normal distribution\n",
    "            if modelConfig['show_process']:\n",
    "                # showing diffusion process\n",
    "                images = sampler.generate_visualize()\n",
    "                num_steps = len(images)\n",
    "                fig, axs = plt.subplots(4, num_steps, figsize=(3*num_steps, 12))\n",
    "                for i, batch_imgs in enumerate(images):\n",
    "                    for j in range(4):  # Plot each image in the batch\n",
    "                        img = batch_imgs[j, 0]  # Extract the j-th image in grayscale (1 channel)\n",
    "                        axs[j, i].imshow(img, cmap='gray')\n",
    "                        axs[j, i].axis('off')\n",
    "                    axs[0, i].set_title(f\"Step {modelConfig['T'] - i * (modelConfig['T'] // 10)}\")\n",
    "        \n",
    "                plt.tight_layout()\n",
    "                plt.savefig(f'{name}/diffusion_process_{e}.png')\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T20:27:30.851315Z",
     "iopub.status.busy": "2024-12-04T20:27:30.850787Z",
     "iopub.status.idle": "2024-12-04T20:27:31.911493Z",
     "shell.execute_reply": "2024-12-04T20:27:31.910604Z",
     "shell.execute_reply.started": "2024-12-04T20:27:30.851283Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!zip -r discrete_checkerboards.zip create_checkerboard1 create_checkerboard2 create_checkerboard3 create_checkerboard4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
